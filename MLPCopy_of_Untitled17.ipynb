{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Y9ZP-oZjoATD",
        "SI1aeBA-dCqC",
        "DllYcUtgovO5",
        "4o02pjAJqdjz",
        "PddyjIzYzu9D",
        "LvNe_bDIz0Wy",
        "w5h1ioy9Rbtl",
        "FzqGlqVxz5mJ",
        "CbgbyxgY0AaN",
        "T4WTGhNs0rep",
        "cq1KuyqhumRh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2022/blob/main/MLPCopy_of_Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  run from here"
      ],
      "metadata": {
        "id": "Y9ZP-oZjoATD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI1aeBA-dCqC"
      },
      "source": [
        "### Model and training code\n",
        "\n",
        "Our model is a coordinate-based multilayer perceptron. In this example, for each input image coordinate $(x,y)$, the model predicts the associated color $(r,g,b)$ or any $(gray)$.\n",
        "\n",
        "![Network diagram](https://user-images.githubusercontent.com/3310961/85066930-ad444580-b164-11ea-9cc0-17494679e71f.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[--xla_force_host_platform_device_count](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html#:~:text=When%20running%20on-,CPU,-you%20can%20always)"
      ],
      "metadata": {
        "id": "Zehuof-K_cZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "import os\n",
        "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'\n",
        "import jax\n",
        "jax.devices()"
      ],
      "metadata": {
        "id": "rUeQSSu5_Jwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "positional_encoding_dims = 6  # Number of positional encodings applied\n",
        "\n",
        "def positional_encoding(inputs):\n",
        "    print(\"positional_encoding start\")\n",
        "    batch_size, _ = inputs.shape;print(inputs.shape)\n",
        "    inputs_freq = jax.vmap(lambda x: inputs * 2.0 ** x)(jnp.arange(positional_encoding_dims));print(inputs_freq.shape)\n",
        "    x = jnp.stack([jnp.sin(inputs_freq), jnp.cos(inputs_freq)]);print(x.shape)\n",
        "    x = x.swapaxes(0, 2);print(x.shape)\n",
        "    x = x.reshape([batch_size, -1]);print(x.shape)\n",
        "    x = jnp.concatenate([inputs, x], axis=-1);print(x.shape)\n",
        "    print(\"positional_encoding end\")\n",
        "    return x\n",
        "\n",
        "# y = np.ones((256, 256, 3))\n",
        "# print(y.shape)\n",
        "# image_height, image_width, cha = y.shape\n",
        "# size = image_height * image_width\n",
        "# yt = np.ones((size, cha))\n",
        "# print(yt.shape)\n",
        "# positional_encoding(yt)\n"
      ],
      "metadata": {
        "id": "z9aPWpu5iJ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# positional_encoding_vmap = jax.vmap(positional_encoding)\n",
        "# ######################################\n",
        "# y = jnp.ones((8, 256, 256, 3))\n",
        "# print(y.shape)\n",
        "# batchsize, image_height, image_width, cha = y.shape\n",
        "# size = image_height * image_width\n",
        "# yt = jnp.ones((batchsize, size, cha))\n",
        "# ######################################\n",
        "# print(\"vmap >>>\")\n",
        "# print(positional_encoding_vmap(yt).shape)\n",
        "\n",
        "# positional_encoding_pmap = jax.pmap(positional_encoding)\n",
        "# print(\"pmap >>>\")\n",
        "# print(positional_encoding_pmap(yt).shape)"
      ],
      "metadata": {
        "id": "YEAZBplw6bKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP MODEL\n",
        "Basically, passing input points through a simple Fourier Feature Mapping enables an MLP to learn high-frequency functions (such as an RGB image) in low-dimensional problem domains (such as a 2D coordinate of pixels)."
      ],
      "metadata": {
        "id": "DllYcUtgovO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax\n",
        "import optax\n",
        "from typing import Any\n",
        "\n",
        "from jax import lax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "num_dense_layers = 8 # Number of dense layers in MLP\n",
        "dense_layer_width = 256 # Dimentionality of dense layers' output space \n",
        "##########################################<< MLP MODEL >>#########################################\n",
        "class MLPModel(nn.Module):\n",
        "    dtype: Any = jnp.float32\n",
        "    precision: Any = lax.Precision.DEFAULT\n",
        "    apply_positional_encoding: bool = apply_positional_encoding\n",
        "    @nn.compact\n",
        "    def __call__(self, input_points):\n",
        "        x = positional_encoding(input_points) if self.apply_positional_encoding else input_points\n",
        "        print(\"network model start\")\n",
        "        print(x.shape)\n",
        "        for i in range(num_dense_layers):\n",
        "            x = nn.Dense(\n",
        "                dense_layer_width,\n",
        "                dtype=self.dtype,\n",
        "                precision=self.precision\n",
        "                )(x)\n",
        "            x = nn.relu(x)\n",
        "            x = jnp.concatenate([x, input_points], axis=-1) if i == 4 else x\n",
        "            print(x.shape)\n",
        "  \n",
        "        x = nn.Dense(1, dtype=self.dtype, precision=self.precision)(x)\n",
        "        print(x.shape)\n",
        "        print(\"network model end\")\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "VRkotxnvvHrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "# !wget https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz\n",
        "# from google.colab import output\n",
        "# output.clear() #to_clear_the_output_console_everytime\n",
        "# import jax.numpy as jnp\n",
        "\n",
        "# data = jnp.load(\"tiny_nerf_data.npz\")\n",
        "# images = data[\"images\"]\n",
        "# poses = data[\"poses\"]\n",
        "# focal = float(data[\"focal\"])\n",
        "# _, image_height, image_width, _ = images.shape\n",
        "# train_images, train_poses = images[:100], poses[:100]\n",
        "# val_image, val_pose = images[101], poses[101]\n",
        "# ############################################\n",
        "# def initialize_model(key, input_pts_shape):\n",
        "#     model = MLPModel()\n",
        "#     initial_params = jax.jit(model.init)({\"params\": key},jnp.ones(input_pts_shape),)\n",
        "#     return model, initial_params[\"params\"]\n",
        "# #############################################\n",
        "# n_devices = jax.local_device_count()\n",
        "# key, rng = jax.random.split(jax.random.PRNGKey(0))\n",
        "# model, params = initialize_model(key, (image_height * image_width, 3))\n"
      ],
      "metadata": {
        "id": "liiEWyFxuwkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #✅\n",
        "# import jax.numpy as jnp\n",
        "# import jax\n",
        "# key, rng = jax.random.split(jax.random.PRNGKey(0))\n",
        "# batch_size_no = 64\n",
        "# x = jnp.ones(shape=(batch_size_no, 32, 32, 3)) # Dummy Input\n",
        "# BATCH, image_height, image_width, channel = x.shape\n",
        "# size = image_height * image_width\n",
        "# yt = jnp.ones((size, channel))\n",
        "# model = MLPModel() # Instantiate the Model\n",
        "\n",
        "# params = model.init(rng, yt) # Initialize the parameters\n",
        "# print(type(params))\n",
        "\n",
        "# params1 = model.apply # Initialize the parameters\n",
        "# print(type(params1))\n",
        "\n",
        "# jax.tree_map(lambda x: x.shape, params) # Check the parameters\n"
      ],
      "metadata": {
        "id": "rg6S9PI0vwV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MODEL SUMMARY { vertical-output: true }\n",
        "#✅\n",
        "# import flax.linen as nn\n",
        "# nn.tabulate(model, rng)(jnp.ones((image_height * image_width, channels)))"
      ],
      "metadata": {
        "id": "hC5jFSB-_P4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize the module"
      ],
      "metadata": {
        "id": "4o02pjAJqdjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#✅\n",
        "!python -m pip install -q -U flax\n",
        "import optax\n",
        "from flax.training import train_state\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "\n",
        "\n",
        "def init_train_state(model, r_key, shape, learning_rate ) -> train_state.TrainState:\n",
        "    print(shape)\n",
        "    # BATCH, image_height, image_width, cha = shape\n",
        "    # size = image_height * image_width\n",
        "    # yt = jnp.ones((size, cha))\n",
        "    init_variables = model.init(r_key, jnp.ones(shape))  # Initialize the Model\n",
        "    optimizer = optax.adam(learning_rate) # Create the optimizer\n",
        "    # Create a State\n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn = model.apply,\n",
        "        tx=optimizer,\n",
        "        params=init_variables['params']\n",
        "    )\n",
        "\n",
        "learning_rate = 1e-4\n",
        "batch_size_no = 64\n",
        "model = MLPModel() # Instantiate the Model\n",
        "key, rng = jax.random.split(jax.random.PRNGKey(0))\n",
        "x = jnp.ones(shape=(batch_size_no, 28, 28, 1)) # Dummy Input\n",
        "_, image_height, image_width, channels = x.shape\n",
        "state = init_train_state( model, rng, (image_height * image_width, channels), learning_rate )\n"
      ],
      "metadata": {
        "id": "rJEuhCl5xuR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(*, logits, labels):\n",
        "    one_hot_encoded_labels = jax.nn.one_hot(labels, num_classes=10)\n",
        "    return optax.softmax_cross_entropy(\n",
        "        logits=logits, labels=one_hot_encoded_labels\n",
        "    ).mean()\n",
        "def compute_metrics(*, logits, labels):\n",
        "  loss = .5 * jnp.mean((logits - labels) ** 2)\n",
        "  loss = lax.pmean(loss, axis_name=\"batch\");print(\"ok4\")\n",
        "  metrics = {\n",
        "      'loss': loss,\n",
        "  }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "f-6Gf-ee-9Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "@jax.jit\n",
        "def train_step(state: train_state.TrainState, batch: jnp.ndarray, rng):\n",
        "    print(batch)\n",
        "    image, label = batch\n",
        "    print(image,\"<<<image\")\n",
        "    print(label,\"<<<label\")    \n",
        "    def loss_fn(params):\n",
        "        logits = state.apply_fn({'params': params}, image);print(\"done1\",logits.shape)\n",
        "        loss =  .5 * jnp.mean((logits - label) ** 2);print(\"done2\",loss.shape)\n",
        "        return loss, logits\n",
        "\n",
        "    # def loss_fn(params):\n",
        "    #     model_fn = lambda x: state.apply_fn({\"params\": params}, x)\n",
        "    #     ray_origins, ray_directions = inputs\n",
        "    #     print(ray_origins)\n",
        "    #     print(ray_directions)\n",
        "    #     rgb, *_ = perform_volume_rendering(\n",
        "    #         model_fn, ray_origins, ray_directions, rng\n",
        "    #     )\n",
        "    #     return jnp.mean((rgb - targets) ** 2)  \n",
        "    print(\"ok1really\")\n",
        "    gradient_fn = jax.value_and_grad(loss_fn, has_aux=True);print(\"ok1\")\n",
        "    (_, logits), grads = gradient_fn(state.params);print(\"ok2\")\n",
        "    #train_loss, gradients_each = jax.value_and_grad(loss_fn)(state.params);print(\"ok3\")\n",
        "    grads = lax.pmean(grads,\"batch\");print(\"ok4\")\n",
        "    # grads = jnp.mean(grads);print(\"ok4\")\n",
        "    state = state.apply_gradients(grads=grads);print(\"ok5\")\n",
        "    # train_loss = jnp.mean(train_loss);print(\"ok6\")\n",
        "    metrics = compute_metrics(logits=logits, labels=label);print(\"ok7\")\n",
        "    return state, metrics\n",
        "\n",
        "parallel_train_step = jax.pmap(train_step, \"batch\")\n",
        "# parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", in_axes = (0, 0, 0))\n",
        "\n",
        "import jax\n",
        "@jax.jit\n",
        "def eval_step(state, batch):\n",
        "    image, label = batch\n",
        "    logits = state.apply_fn({'params': state.params}, image)\n",
        "    return compute_metrics(logits=logits, labels=label)\n"
      ],
      "metadata": {
        "id": "wskhkyy49MIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checkpoints management"
      ],
      "metadata": {
        "id": "PddyjIzYzu9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(ckpt_path, state):\n",
        "    with open(ckpt_path, \"wb\") as outfile:\n",
        "        outfile.write(msgpack_serialize(to_state_dict(state)))\n",
        "    \n",
        "\n",
        "\n",
        "def load_checkpoint(ckpt_path, ckpt_file, state):\n",
        "    ckpt_path = os.path.join(ckpt_path, ckpt_file)\n",
        "    with open(ckpt_path, \"rb\") as data_file:\n",
        "        byte_data = data_file.read()\n",
        "    return from_bytes(state, byte_data)\n",
        "\n",
        "\n",
        "def accumulate_metrics(metrics):\n",
        "    metrics = jax.device_get(metrics)\n",
        "    return {\n",
        "        k: np.mean([metric[k] for metric in metrics])\n",
        "        for k in metrics[0]\n",
        "    }"
      ],
      "metadata": {
        "id": "6e5D7TaR8os4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train & evaluation function"
      ],
      "metadata": {
        "id": "LvNe_bDIz0Wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1UgWEotThxnP-Vh-h83-VcTPMkKWmgCDe #downloading MAP-DEM "
      ],
      "metadata": {
        "id": "BoQeqWgTkX3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -U tifffile imagecodecs matplotlib lxml zarr fsspec\n"
      ],
      "metadata": {
        "id": "Sh6EJ9Wbsb3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "import imagecodecs\n",
        "from imagecodecs import imread, imwrite\n",
        "fp = r'/content/a.tif'\n",
        "image = imread(\"/content/a.tif\")\n",
        "b = image.reshape(-1,1)\n",
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFJvGVWttn1l",
        "outputId": "a3287799-c04d-4abf-8453-fd2ed0341795"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16493480, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install rasterio\n"
      ],
      "metadata": {
        "id": "E7ILCMFnxUVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "# fp = r'/content/a.tif'\n",
        "# img = rasterio.open(fp)\n",
        "show(image)\n",
        "print(img.count) #to print number of bands\n",
        "newsize = (28, 28)\n",
        "def imageGRAY(argv):\n",
        "    im = imread(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,1)\n",
        "    return tvt, tvu\n",
        "x, x1 = imageGRAY(\"/content/a.tif\")\n",
        "print(x.shape, x1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "PJJCBhyEmIWy",
        "outputId": "acc2f4c1-22b4-4296-a772-edc3d0a50158"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "() (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://live.staticflickr.com/7492/15677707699_d9d67acf9d_b.jpg -O a.jpg\n",
        "\n",
        "newsize = (28, 28)\n",
        "from PIL import Image, ImageFilter\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def imageGRAY(argv):\n",
        "    im = Image.open(argv).convert('L')\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,1)\n",
        "    return tvt, tvu\n",
        "def imageRGB(argv):\n",
        "    im = Image.open(argv)\n",
        "    tvt, tvu = jnp.asarray(im.resize(newsize)),jnp.asarray(im.resize(newsize)).reshape(-1,3)\n",
        "    return tvt, tvu\n",
        "x, x1 = imageGRAY(\"/content/a.jpg\")\n",
        "print(x.shape)# mnist IMAGES are 28x28=784 pixels\n",
        "y, y1 = imageRGB(\"/content/a.jpg\")\n",
        "print(y.shape,y1.shape,\"<< y shape\",x.shape,x1.shape,\"<< y shape\")# mnist IMAGES are 28x28=784 pixels\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(x);plt.show()\n",
        "plt.imshow(y);plt.show()\n",
        "plt.imshow((y1[0]-x1).reshape(28,-1));plt.show()\n",
        "plt.imshow((y1[1]-x1).reshape(28,-1));plt.show()\n",
        "plt.imshow((y1[2]-x1).reshape(28,-1));plt.show()\n",
        "\n",
        "\n",
        "# batch = y1, x1  # jnp.ones((28*28,1)),jnp.ones((28*28,1)) OR jnp.ones((2, 28*28, 1))\n",
        "# shapea, channels = y1.shape\n",
        "# state = init_train_state( model, rng, (shapea, channels), learning_rate )\n",
        "# for e in range(150):\n",
        "#   state, metrics = train_step(state, batch, rng)\n",
        "#   print(metrics)"
      ],
      "metadata": {
        "id": "QjJ1VIiKgs0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #✅\n",
        "# import os\n",
        "# os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'\n",
        "# import jax\n",
        "# jax.devices()\n",
        "# import jax.numpy as jnp\n",
        "# from jax import pmap\n",
        "# a = jnp.arange(8*10).reshape((8, 2,5))\n",
        "# b = 2\n",
        "# print(type(a));print(a)\n",
        "# def f(x,y):a = x**2+y**2;return a\n",
        "# ff = pmap(f, in_axes=(0,None))\n",
        "# result = ff(a,b)\n",
        "# print(type(result));print(result)\n",
        "# num_devices = jax.device_count()\n",
        "\n",
        "# shape_prefix = (num_devices, 1);print(shape_prefix)"
      ],
      "metadata": {
        "id": "gcib9OwKfNO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_devices = jax.device_count()\n",
        "ddy = jnp.asarray((y1,y1,y1,y1,y1,y1,y1,y1))       # rgb images (width * height, 3)\n",
        "print(ddy.shape,\"<<< ddy shape\")\n",
        "ddx = jnp.asarray((x1,x1,x1,x1,x1,x1,x1,x1))    #gray images (width * height, 1)\n",
        "shape_prefix = (num_devices, 1);print(shape_prefix);print(ddy.shape,\"<<<< ???\")\n",
        "# ddy = ddy.reshape(shape_prefix + ddy.shape[1:]);print(ddy.shape,\"<< train_images_incorrect\")\n",
        "# ddx = ddx.reshape(shape_prefix + ddx.shape[1:]);print(ddx.shape,\"<< train_images_incorrect\")\n",
        "batch = ddy, ddx  # jnp.ones((28*28,1)),jnp.ones((28*28,1)) OR jnp.ones((2, 28*28, 1))\n",
        "print(len(batch),\"<<< batch\")\n",
        "vv, shapea, channels = ddy.shape\n",
        "######################\n",
        "rng = jax.random.PRNGKey(0)\n",
        "dropout_rngs = jax.random.split(rng, jax.local_device_count())\n",
        "######################\n",
        "state = init_train_state( model, rng, (shapea, channels), learning_rate )\n",
        "state = flax.jax_utils.replicate(state)\n",
        "\n",
        "for e in range(500):\n",
        "  state, metrics = parallel_train_step(state, batch, dropout_rngs)\n",
        "  print(\"<<✅✅✅epoc : \",e,\" complete✅✅✅>>\\n\",metrics)"
      ],
      "metadata": {
        "id": "qUpVOU52BWfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ❌❌❌❌❌❌❌doesnot work >>>"
      ],
      "metadata": {
        "id": "w5h1ioy9Rbtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 32\n",
        "import datasets\n",
        "train_images, train_labels, test_images, test_labels = datasets.mnist()\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "import jax\n",
        "num_devices = jax.device_count()\n",
        "def data_stream():\n",
        "  key, rng = jax.random.split(jax.random.PRNGKey(0))\n",
        "  while True:\n",
        "    perm = jax.random.permutation(rng, num_train); print(perm.shape)\n",
        "    for i in range(num_batches):\n",
        "      batch_idx = perm[i * batch_size:(i + 1) * batch_size]; print(batch_idx)\n",
        "      images, labels = train_images[batch_idx], train_labels[batch_idx]; print(images.shape,\"<< train_images_incorrect\");print(labels.shape,\"<< train_images_correct\")\n",
        "      # For this SPMD example, we reshape the data batch dimension into two\n",
        "      # batch dimensions, one of which is mapped over parallel devices.\n",
        "      batch_size_per_device, ragged = divmod(images.shape[0], num_devices);print(batch_size_per_device,\"<<< batch_size_per_device\")\n",
        "      if ragged:\n",
        "        msg = \"batch size must be divisible by device count, got {} and {}.\"\n",
        "        raise ValueError(msg.format(batch_size, num_devices))\n",
        "      shape_prefix = (num_devices, batch_size_per_device);print(shape_prefix)\n",
        "      images = images.reshape(shape_prefix + images.shape[1:]);print(images.shape,\"<< train_images_incorrect\")\n",
        "      labels = labels.reshape(shape_prefix + labels.shape[1:]);print(labels.shape,\"<< train_images_correct\")\n",
        "      return images, labels\n",
        "batches = data_stream()\n"
      ],
      "metadata": {
        "id": "i7oLNzL4U5m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_batches = tf.data.experimental.cardinality(train_dataset)\n",
        "train_datagen = iter(tfds.as_numpy(train_dataset))\n",
        "batch = next(train_datagen)\n",
        "batch = jnp.ones((28*28,1)),jnp.ones((28*28,1))  # jnp.ones((28*28,1)),jnp.ones((28*28,1)) OR jnp.ones((2, 28*28, 1))\n",
        "# state = flax.jax_utils.replicate(state)\n",
        "state = init_train_state( model, rng, (image_height * image_width, channels), learning_rate )\n",
        "for e in range(50):\n",
        "  state, metrics = train_step(state, batch, rng)\n",
        "  print(metrics)"
      ],
      "metadata": {
        "id": "_W-fMd-P07bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_and_evaluate(train_dataset, eval_dataset, test_dataset, state: train_state.TrainState, epochs: int,):\n",
        "    num_train_batches = tf.data.experimental.cardinality(train_dataset)\n",
        "    num_eval_batches = tf.data.experimental.cardinality(eval_dataset)\n",
        "    num_test_batches = tf.data.experimental.cardinality(test_dataset)\n",
        "   \n",
        "    for epoch in tqdm(range(1, epochs + 1)):\n",
        "        best_eval_loss = 1e6\n",
        "        # ============== Training ============== #\n",
        "        train_batch_metrics = []\n",
        "        train_datagen = iter(tfds.as_numpy(train_dataset))\n",
        "        for batch_idx in range(num_train_batches):\n",
        "            batch = next(train_datagen)\n",
        "            state, metrics = train_step(state, batch, rng)\n",
        "            train_batch_metrics.append(metrics)\n",
        "        train_batch_metrics = accumulate_metrics(train_batch_metrics)\n",
        "        print('TRAIN (%d/%d): Loss: %.4f' % (\n",
        "                epoch, epochs, train_batch_metrics['loss'],\n",
        "              ))\n",
        "        # ============== Validation ============= #\n",
        "        eval_batch_metrics = []\n",
        "        eval_datagen = iter(tfds.as_numpy(eval_dataset))\n",
        "        for batch_idx in range(num_eval_batches):\n",
        "            batch = next(eval_datagen)\n",
        "            metrics = eval_step(state, batch)\n",
        "            eval_batch_metrics.append(metrics)\n",
        "        eval_batch_metrics = accumulate_metrics(eval_batch_metrics)\n",
        "        print('EVAL (%d/%d):  Loss: %.4f\\n' % (\n",
        "                epoch, epochs, eval_batch_metrics['loss'],\n",
        "              ))    \n",
        "\n",
        "        if eval_batch_metrics['loss'] < best_eval_loss:\n",
        "            save_checkpoint(\"checkpoint.msgpack\", state)\n",
        "\n",
        "    restored_state = load_checkpoint(\"checkpoint.msgpack\", state)\n",
        "    test_batch_metrics = []\n",
        "    test_datagen = iter(tfds.as_numpy(test_dataset))\n",
        "    for batch_idx in range(num_test_batches):\n",
        "        batch = next(test_datagen)\n",
        "        metrics = eval_step(restored_state, batch)\n",
        "        test_batch_metrics.append(metrics)\n",
        "    \n",
        "    test_batch_metrics = accumulate_metrics(test_batch_metrics)\n",
        "    print(\n",
        "        'Test: Loss: %.4f,' % (\n",
        "            test_batch_metrics['loss'],\n",
        "        )\n",
        "    )\n",
        "    # Log Metrics to Weights & Biases\n",
        "    history = {\n",
        "        \"Train Loss\": train_batch_metrics['loss'],\n",
        "        \"Validation Loss\": eval_batch_metrics['loss'],\n",
        "    }\n",
        "    return state, restored_state, history\n",
        "\n"
      ],
      "metadata": {
        "id": "3wWR27rO-yGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loading 'mnist' data"
      ],
      "metadata": {
        "id": "FzqGlqVxz5mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title @inproceedings{zhou2017scene, title={Scene Parsing through ADE20K Dataset}, author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio}, booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, year={2017} }\n",
        "#✅✅\n",
        "import tensorflow_datasets as tfds\n",
        "(full_train_set, test_dataset), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "validation_split = 0.2\n",
        "def normalize_img(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "DNQMoyp_HPM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#✅✅\n",
        "import tensorflow as tf\n",
        "batch_size = 64\n",
        "full_train_set = full_train_set.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "num_data = tf.data.experimental.cardinality(full_train_set).numpy()\n",
        "print(\"Total number of data points:\", num_data)\n",
        "train_dataset = full_train_set.take(num_data * (1 - validation_split))\n",
        "val_dataset = full_train_set.take(num_data * (validation_split))\n",
        "print(\"Number of train data points:\",tf.data.experimental.cardinality(train_dataset).numpy())\n",
        "print(\"Number of val data points:\",tf.data.experimental.cardinality(val_dataset).numpy())\n",
        "#############TRAIN##################\n",
        "train_dataset = train_dataset.cache();print(len(train_dataset))\n",
        "train_dataset = train_dataset.shuffle(tf.data.experimental.cardinality(train_dataset).numpy());print(train_dataset)\n",
        "train_dataset = train_dataset.batch(batch_size);print(train_dataset)\n",
        "#############TRAIN(EVALUATE)##################\n",
        "val_dataset = val_dataset.cache()\n",
        "val_dataset = val_dataset.shuffle(tf.data.experimental.cardinality(val_dataset).numpy())\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#############TEST##################\n",
        "test_dataset = test_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "print(\"Number of test data points:\",tf.data.experimental.cardinality(test_dataset).numpy())\n",
        "test_dataset = test_dataset.cache()\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "g7_nuCh5b12e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_batches = tf.data.experimental.cardinality(train_dataset)\n",
        "num_train_batches"
      ],
      "metadata": {
        "id": "atLCxN738JSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run inferences"
      ],
      "metadata": {
        "id": "CbgbyxgY0AaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# state, inference_state, history = train_and_evaluate(state, parallelized_train_step, eval_step)\n",
        "\n",
        "\n",
        "# train_dataset, eval_dataset, test_dataset, state, epochs\n",
        "from tqdm.notebook import tqdm\n",
        "epochs = 15\n",
        "state, best_state, history = train_and_evaluate(\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    test_dataset,\n",
        "    state,\n",
        "    epochs,\n",
        ")"
      ],
      "metadata": {
        "id": "ABcUcSG65REH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "_ULguI_OmYwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# go"
      ],
      "metadata": {
        "id": "T4WTGhNs0rep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import imageio\n",
        "import requests\n",
        "from typing import Any\n",
        "import ipywidgets as widgets\n",
        "from functools import partial\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip3 install -q -U flax\n",
        "\n",
        "import jax\n",
        "import flax\n",
        "import optax\n",
        "from jax import lax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state, common_utils\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "\n",
        "\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n"
      ],
      "metadata": {
        "id": "_pHA9kuNvNf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://www.kaggle.com/code/odins0n/jax-flax-tf-data-vision-transformers-tutorial\n",
        "\n",
        "\n",
        "# Detect if Kaggle Notebook has access to TPUs or not\n",
        "if 'TPU_NAME' in os.environ:\n",
        "    import requests\n",
        "    if 'TPU_DRIVER_MODE' not in globals():\n",
        "        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n",
        "        resp = requests.post(url)\n",
        "        TPU_DRIVER_MODE = 1\n",
        "    from jax.config import config\n",
        "    jax_xla_backend = \"tpu_driver\"\n",
        "    jax_backend_target = os.environ['TPU_NAME']\n",
        "    print(\"TPU DETECTED!\")\n",
        "    print('Registered TPU:', jax_backend_target)\n",
        "\n",
        "\n",
        "# Detect if Google Colab Notebook has access to TPUs or not\n",
        "elif \"COLAB_TPU_ADDR\" in os.environ:\n",
        "    import jax.tools.colab_tpu\n",
        "    jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "\n",
        "else:\n",
        "    print('No TPU detected.')\n",
        "\n",
        "\n",
        "DEVICE_COUNT = len(jax.local_devices())\n",
        "TPU = DEVICE_COUNT==8\n",
        "\n",
        "\n",
        "if TPU:\n",
        "    print(\"8 cores of TPU ( Local devices in Jax ):\")\n",
        "    print('\\n'.join(map(str,jax.local_devices())))\n"
      ],
      "metadata": {
        "id": "eaTPv-kSvMA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# sync all experiment configs with Weights and Biases\n",
        "\n",
        "near_bound = 2. # Near Bound of sample space for 3d points\n",
        "far_bound = 6.  # Far Bound of sample space for 3d points\n",
        "batch_size = int(1e4) # Batch Size\n",
        "num_sample_points = 256 # Number of points to be sampled across the volume\n",
        "epsilon = 1e10 # Hyperparameter for volume rendering\n",
        "apply_positional_encoding = True # Apply posittional encoding to the input or not\n",
        "positional_encoding_dims = 3 # Number of positional encodings applied\n",
        "num_dense_layers = 5 # Number of dense layers in MLP\n",
        "dense_layer_width = 256 # Dimentionality of dense layers' output space \n",
        "learning_rate = 5e-4 # Learning Rate\n",
        "train_epochs = 1000 # Number of training epochs\n",
        "plot_interval = 100 # Epoch interval for plotting results during training\n"
      ],
      "metadata": {
        "id": "Dj-uVwfWvJmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding_dims = 3 # Number of positional encodings applied\n",
        "def positional_encoding(inputs):\n",
        "    batch_size, _ = inputs.shape;                                                   print(inputs.shape)\n",
        "    # Applying vmap transform to vectorize the multiplication operation\n",
        "    f = jax.vmap(lambda x: inputs * 2.0 ** x)(jnp.arange(positional_encoding_dims));print(f.shape)\n",
        "    fy = jnp.stack([jnp.sin(f), jnp.cos(f)]);                                       print(fy)\n",
        "    fy = fy.swapaxes(0, 2).reshape([batch_size, -1]);                               print(fy)\n",
        "    fy = jnp.concatenate([inputs, fy], axis=-1);                                    print(fy)\n",
        "    return fy\n"
      ],
      "metadata": {
        "id": "tqiAfLsYvFdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(10000, 3)\n",
        "\n",
        "\n",
        "(3, 10000, 3)\n",
        "\n",
        "Traced<ShapedArray(float32[2,3,10000,3])>with<DynamicJaxprTrace(level=0/1)>\n",
        "\n",
        "Traced<ShapedArray(float32[10000,18])>with<DynamicJaxprTrace(level=0/1)>\n",
        "\n",
        "Traced<ShapedArray(float32[10000,21])>with<DynamicJaxprTrace(level=0/1)>"
      ],
      "metadata": {
        "id": "uR_Bu2DpbChW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test mnist pmap gpu 1000 epocs runtime 9 minutes"
      ],
      "metadata": {
        "id": "cq1KuyqhumRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile datasets.py\n",
        "# Copyright 2018 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Datasets used in examples.\"\"\"\n",
        "\n",
        "\n",
        "import array\n",
        "import gzip\n",
        "import os\n",
        "from os import path\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "_DATA = \"/tmp/jax_example_data/\"\n",
        "\n",
        "\n",
        "def _download(url, filename):\n",
        "  \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "  if not path.exists(_DATA):\n",
        "    os.makedirs(_DATA)\n",
        "  out_file = path.join(_DATA, filename)\n",
        "  if not path.isfile(out_file):\n",
        "    urllib.request.urlretrieve(url, out_file)\n",
        "    print(f\"downloaded {url} to {_DATA}\")\n",
        "\n",
        "\n",
        "def _partial_flatten(x):\n",
        "  \"\"\"Flatten all but the first dimension of an ndarray.\"\"\"\n",
        "  return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "\n",
        "def _one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "\n",
        "def mnist_raw():\n",
        "  \"\"\"Download and parse the raw MNIST dataset.\"\"\"\n",
        "  # CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
        "  base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "  def parse_labels(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _ = struct.unpack(\">II\", fh.read(8))\n",
        "      return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "  def parse_images(filename):\n",
        "    with gzip.open(filename, \"rb\") as fh:\n",
        "      _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "      return np.array(array.array(\"B\", fh.read()),\n",
        "                      dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "  for filename in [\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "                   \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"]:\n",
        "    _download(base_url + filename, filename)\n",
        "\n",
        "  train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "  train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "  test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "  test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(permute_train=False):\n",
        "  \"\"\"Download, parse and process MNIST data to unit scale and one-hot labels.\"\"\"\n",
        "  train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "\n",
        "  train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "  test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "  train_labels = _one_hot(train_labels, 10)\n",
        "  test_labels = _one_hot(test_labels, 10)\n",
        "\n",
        "  if permute_train:\n",
        "    perm = np.random.RandomState(0).permutation(train_images.shape[0])\n",
        "    train_images = train_images[perm]\n",
        "    train_labels = train_labels[perm]\n",
        "\n",
        "  return train_images, train_labels, test_images, test_labels"
      ],
      "metadata": {
        "id": "pn2wusArvMza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[datasets](https://github.com/google/jax/blob/main/examples/datasets.py) link\n",
        "\n",
        "[spmd_mnist_classifier_fromscratch](https://github.com/google/jax/blob/main/examples/spmd_mnist_classifier_fromscratch.py) link"
      ],
      "metadata": {
        "id": "mBuFyBnWy9S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2018 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"An MNIST example with single-program multiple-data (SPMD) data parallelism.\n",
        "\n",
        "The aim here is to illustrate how to use JAX's `pmap` to express and execute\n",
        "SPMD programs for data parallelism along a batch dimension, while also\n",
        "minimizing dependencies by avoiding the use of higher-level layers and\n",
        "optimizers libraries.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from functools import partial\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "\n",
        "import jax\n",
        "from jax import jit, grad, pmap\n",
        "from jax.scipy.special import logsumexp\n",
        "from jax.tree_util import tree_map\n",
        "from jax import lax\n",
        "import jax.numpy as jnp\n",
        "import datasets\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "def init_random_params(scale, layer_sizes, rng=npr.RandomState(0)):\n",
        "  return [(scale * rng.randn(m, n), scale * rng.randn(n))\n",
        "          for m, n, in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "\n",
        "def predict(params, inputs):\n",
        "  activations = inputs\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(activations, w) + b\n",
        "    activations = jnp.tanh(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = jnp.dot(activations, final_w) + final_b\n",
        "  return logits - logsumexp(logits, axis=1, keepdims=True)\n",
        "\n",
        "def loss(params, batch):\n",
        "  inputs, targets = batch\n",
        "  preds = predict(params, inputs)\n",
        "  return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
        "\n",
        "@jit\n",
        "def accuracy(params, batch):\n",
        "  inputs, targets = batch\n",
        "  target_class = jnp.argmax(targets, axis=1)\n",
        "  predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
        "  return jnp.mean(predicted_class == target_class)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  layer_sizes = [784, 1024, 1024, 10]\n",
        "  param_scale = 0.1\n",
        "  step_size = 0.001\n",
        "  num_epochs = 1000\n",
        "  batch_size = 128\n",
        "\n",
        "  train_images, train_labels, test_images, test_labels = datasets.mnist()\n",
        "  num_train = train_images.shape[0]\n",
        "  num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "  num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "  # For this manual SPMD example, we get the number of devices (e.g. GPUs or\n",
        "  # TPU cores) that we're using, and use it to reshape data minibatches.\n",
        "  num_devices = jax.device_count()\n",
        "  def data_stream():\n",
        "    rng = npr.RandomState(0)\n",
        "    while True:\n",
        "      perm = rng.permutation(num_train)\n",
        "      for i in range(num_batches):\n",
        "        batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "        images, labels = train_images[batch_idx], train_labels[batch_idx]\n",
        "        # For this SPMD example, we reshape the data batch dimension into two\n",
        "        # batch dimensions, one of which is mapped over parallel devices.\n",
        "        batch_size_per_device, ragged = divmod(images.shape[0], num_devices)\n",
        "        if ragged:\n",
        "          msg = \"batch size must be divisible by device count, got {} and {}.\"\n",
        "          raise ValueError(msg.format(batch_size, num_devices))\n",
        "        shape_prefix = (num_devices, batch_size_per_device)\n",
        "        images = images.reshape(shape_prefix + images.shape[1:])\n",
        "        labels = labels.reshape(shape_prefix + labels.shape[1:])\n",
        "        yield images, labels\n",
        "  batches = data_stream()\n",
        "\n",
        "  @partial(pmap, axis_name='batch')\n",
        "  def spmd_update(params, batch):\n",
        "    grads = grad(loss)(params, batch)\n",
        "    # We compute the total gradients, summing across the device-mapped axis,\n",
        "    # using the `lax.psum` SPMD primitive, which does a fast all-reduce-sum.\n",
        "    grads = [(lax.psum(dw, 'batch'), lax.psum(db, 'batch')) for dw, db in grads]\n",
        "    return [(w - step_size * dw, b - step_size * db)\n",
        "            for (w, b), (dw, db) in zip(params, grads)]\n",
        "\n",
        "  # We replicate the parameters so that the constituent arrays have a leading\n",
        "  # dimension of size equal to the number of devices we're pmapping over.\n",
        "  init_params = init_random_params(param_scale, layer_sizes)\n",
        "  replicate_array = lambda x: np.broadcast_to(x, (num_devices,) + x.shape)\n",
        "  replicated_params = tree_map(replicate_array, init_params)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    for _ in range(num_batches):\n",
        "      replicated_params = spmd_update(replicated_params, next(batches))\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    # We evaluate using the jitted `accuracy` function (not using pmap) by\n",
        "    # grabbing just one of the replicated parameter values.\n",
        "    params = tree_map(lambda x: x[0], replicated_params)\n",
        "    train_acc = accuracy(params, (train_images, train_labels))\n",
        "    test_acc = accuracy(params, (test_images, test_labels))\n",
        "    output.clear() #to_clear_the_output_console_everytime\n",
        "    print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
        "    print(f\"Training set accuracy {train_acc}\")\n",
        "    print(f\"Test set accuracy {test_acc}\")"
      ],
      "metadata": {
        "id": "aVJlb1-tuorJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}