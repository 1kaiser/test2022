{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MODIS_MOD09A1_Snow_Cover_Area.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2022/blob/main/MODIS_MOD09A1_Snow_Cover_Area.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " >MOD09A1.061 data DOWNLOAD & PROCESSING calculating NDSI  > 0.4 && band2 reflectance is more than 11%"
      ],
      "metadata": {
        "id": "hlcgiXaXS1-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v6GiEeRvYbBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0894da-9a35-495a-a1e1-7a2d8210018d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NbFxO-hu1Tx"
      },
      "source": [
        "## **RUNNING CODE NDSI *MOD09A1.061* 8 DAY**  \n",
        "## ðŸŒ¨ï¸â„ï¸ðŸ”ï¸  **SNOW COVER AREA**  ðŸ”ï¸â„ï¸ðŸŒ¨ï¸"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "Xx-WJA_Bhm3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca8b83e-47a4-4d5c-c36c-a80222bd9a7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pre requisites please run this section >>>>"
      ],
      "metadata": {
        "id": "E8YMNHt3soFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyModis\n",
        "!sudo apt-get install jq"
      ],
      "metadata": {
        "id": "79zaMlOGsmAE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown https://drive.google.com/uc?id=1oyqXeHZgaTOjLod-Vqz-VAzS88O13JDr\n",
        "# !unzip /content/beasBasinShapeFile.zip -d /content"
      ],
      "metadata": {
        "id": "s73AxlUG7E0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1pQH1VU_KX1TIbJLHvptxAFup10EUj6nX\n",
        "!unzip /content/correct.zip"
      ],
      "metadata": {
        "id": "BuiH0mvfFZix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process Data Here"
      ],
      "metadata": {
        "id": "PmqyTwzIyPI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PROCESSING IMAGES FOR SNOW COVER >>> SAVING  *.TXT FILE { vertical-output: true }\n",
        "import os\n",
        "import pymodis\n",
        "import gdalnumeric\n",
        "#to clear output\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "image_dir = r'/content/drive/MyDrive/OUT/data/MOD09A1061/files/'\n",
        "#############################################################################\n",
        "prefix = \"sur_refl_\"\n",
        "bandend = [\"b01\", \"b02\", \"b03\", \"b04\", \"b05\", \"b06\", \"b07\", \"day_of_year\", \"qc_500m\", \"raz\", \"state_500m\", \"szen\", \"vzen\"]\n",
        "DayOY = \"_doy\\[0-9]+_aid0001\"\n",
        "fileExt = r'.tif'\n",
        "expression_b2 = prefix+bandend[1]\n",
        "expression_b4 = prefix+bandend[3]\n",
        "expression_b6 = prefix+bandend[5]\n",
        "\n",
        "temp_dir = r'/content/'\n",
        "import os\n",
        "\n",
        "imgs_list_b2 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b2)]\n",
        "imgs_list_b4 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b4)]\n",
        "imgs_list_b6 = [f for f in os.listdir(image_dir) if f.__contains__(expression_b6)]\n",
        "imgs_list_b2.sort()\n",
        "imgs_list_b4.sort()\n",
        "imgs_list_b6.sort()\n",
        "imgs_path_b2 = [os.path.join(image_dir, i) for i in imgs_list_b2 if i != 'outputs']\n",
        "imgs_path_b4 = [os.path.join(image_dir, i) for i in imgs_list_b4 if i != 'outputs']\n",
        "imgs_path_b6 = [os.path.join(image_dir, i) for i in imgs_list_b6 if i != 'outputs']\n",
        "print(len(imgs_path_b2),len(imgs_path_b4),len(imgs_path_b6))\n",
        "###############################################################################\n",
        "for i, file_name in enumerate(imgs_path_b2):\n",
        "    print('ok')\n",
        "    print(file_name)\n",
        "    pathb2 = imgs_list_b2[i]\n",
        "    pathb4 = imgs_list_b4[i]\n",
        "    pathb6 = imgs_list_b6[i]\n",
        "    #creating file NDSI\n",
        "    !gdal_calc.py \\\n",
        "      --overwrite \\\n",
        "      --type=Float32 \\\n",
        "      -A {image_dir}{pathb4} \\\n",
        "      --A_band 1 \\\n",
        "      -B {image_dir}{pathb6} \\\n",
        "      --B_band 1 \\\n",
        "      --outfile={temp_dir}\"NDSI_result.tif\" \\\n",
        "      --calc=\"(A.astype(float) - B)/(A.astype(float) + B)\"\n",
        "\n",
        "    !gdal_calc.py \\\n",
        "      --overwrite \\\n",
        "      --type=Float32 \\\n",
        "      -A {image_dir}{pathb2} \\\n",
        "      --A_band 1 \\\n",
        "      -B {temp_dir}\"NDSI_result.tif\" \\\n",
        "      --B_band 1 \\\n",
        "      --outfile={temp_dir}\"BothCheck_result.tif\" \\\n",
        "      --calc=\"(B.astype(float)>=0.4)*(A.astype(float)>0.11*A.astype(float))\"#--calc=\"(A.astype(float)>0.011*A.astype(float))\"#\n",
        "    \n",
        "    !rm -r {temp_dir}\"NDSI_result.tif\"\n",
        "    #deleting file\n",
        "\n",
        "    #counting Snow and Non-Snowpixels  \n",
        "    #import gdalnumeric\n",
        "    raster_file = gdalnumeric.LoadFile(temp_dir+\"BothCheck_result.tif\")\n",
        "    pixel_count_snow = (raster_file ==1).sum()\n",
        "    pixel_count_notsnow = (raster_file ==0).sum()\n",
        "    print(\"snow:\",pixel_count_snow,\" not snow:\",pixel_count_notsnow)\n",
        "\n",
        "    temp_dir_elevations = r\"/content/correct/\"\n",
        "    elev = [ 1001000, 10002000, 20003000, 30004000, 40005000, 50006000, 60007000]\n",
        "    SC_values = []\n",
        "    for j, elevations in enumerate(elev):\n",
        "      !gdalwarp \\\n",
        "        -ot Float32 \\\n",
        "        -cutline {temp_dir_elevations}E{elev[j]}.shp  -crop_to_cutline \\\n",
        "        {temp_dir}\"BothCheck_result.tif\" \\\n",
        "        {temp_dir}result_\"{str(j)}\".tif\n",
        "\n",
        "      #counting Snow and Non-Snowpixels  \n",
        "      #import gdalnumeric\n",
        "      raster_file = gdalnumeric.LoadFile(temp_dir+\"result_\"+str(j)+\".tif\")\n",
        "      pixel_nos_snow = (raster_file ==1).sum()\n",
        "      pixel_nos_notsnow = (raster_file ==0).sum()\n",
        "      SC_values.append(pixel_nos_snow)\n",
        "      SC_values.append(pixel_nos_notsnow)\n",
        "      !rm -r {temp_dir}result_{str(j)}.tif\n",
        "\n",
        "    m1 = !gdalinfo -json {temp_dir}\"BothCheck_result.tif\" | jq -r .geoTransform \n",
        "\n",
        "    !rm -r {temp_dir}\"BothCheck_result.tif\"\n",
        "    #deleting file\n",
        "\n",
        "    coonstant_c = float(m1[2][9:9+16])*float(m1[6][9+1:9+16+1])*10000\n",
        "    area_sc_values = [number * coonstant_c for number in SC_values]\n",
        "    print(str(coonstant_c*pixel_count_snow),str(coonstant_c*pixel_count_notsnow),str(coonstant_c*pixel_count_snow+coonstant_c*pixel_count_notsnow))\n",
        "    lines = str(pathb2[25:25+10] + \",\" + str(coonstant_c*pixel_count_snow) + \",\" + str(coonstant_c*pixel_count_notsnow) + \",\" + str(area_sc_values)[1:-1])\n",
        "    with open(temp_dir + \"out.txt\", \"a+\", encoding = \"utf-8\") as f:\n",
        "        f.writelines('\\n' + lines)\n",
        "        #output.clear() #to_clear_the_output_console_everytime\n",
        "    "
      ],
      "metadata": {
        "id": "O4TyjxtGGWah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b8a2d47-f5ce-4e85-9792-e5fae2487ce9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1021 1021 1021\n",
            "ok\n",
            "/content/drive/MyDrive/OUT/data/MOD09A1061/files/MOD09A1.061_sur_refl_b02_doy2000049_aid0001.tif\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "snow: 0  not snow: 0\n",
            "ERROR 1: Output dataset /content/result_0.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_1.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_2.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_3.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_4.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_5.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "ERROR 1: Output dataset /content/result_6.tif exists,\n",
            "but some command line options were provided indicating a new dataset\n",
            "should be created.  Please delete existing dataset and run again.\n",
            "\n",
            "0.0 0.0 0.0\n",
            "ok\n",
            "/content/drive/MyDrive/OUT/data/MOD09A1061/files/MOD09A1.061_sur_refl_b02_doy2000057_aid0001.tif\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "snow: 19453  not snow: 43322\n",
            "Creating output file that is 303P x 167L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_0.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 338P x 196L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_1.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 305P x 219L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_2.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 344P x 223L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_3.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 355P x 192L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_4.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 265P x 182L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_5.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 116P x 92L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_6.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "3377.256943833837 7521.180554195727 10898.437498029565\n",
            "ok\n",
            "/content/drive/MyDrive/OUT/data/MOD09A1061/files/MOD09A1.061_sur_refl_b02_doy2000065_aid0001.tif\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "snow: 19806  not snow: 42895\n",
            "Creating output file that is 303P x 167L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_0.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 338P x 196L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_1.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 305P x 219L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_2.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 344P x 223L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_3.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 355P x 192L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_4.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 265P x 182L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_5.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 116P x 92L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_6.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "3438.5416660449787 7447.048609764685 10885.590275809664\n",
            "ok\n",
            "/content/drive/MyDrive/OUT/data/MOD09A1061/files/MOD09A1.061_sur_refl_b02_doy2000073_aid0001.tif\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "snow: 18325  not snow: 44354\n",
            "Creating output file that is 303P x 167L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_0.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
            "Creating output file that is 338P x 196L.\n",
            "Processing input file /content/BothCheck_result.tif.\n",
            "Using internal nodata values (e.g. 3.40282e+38) for image /content/BothCheck_result.tif.\n",
            "Copying nodata values from source /content/BothCheck_result.tif to destination /content/result_1.tif.\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5ae7e87a2b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0;31m#counting Snow and Non-Snowpixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;31m#import gdalnumeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m       \u001b[0mraster_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdalnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"result_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m       \u001b[0mpixel_nos_snow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraster_file\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mpixel_nos_notsnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraster_file\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/osgeo/gdal_array.py\u001b[0m in \u001b[0;36mLoadFile\u001b[0;34m(filename, xoff, yoff, xsize, ysize, buf_xsize, buf_ysize, buf_type, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m    222\u001b[0m               \u001b[0mresample_alg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRIORA_NearestNeighbour\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m               callback=None, callback_data=None ):\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't open \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetLastErrorMsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mOpen\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;34m\"\"\"Open(char const * utf8_path, GDALAccess eAccess) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpenEx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: `/content/result_1.tif' not recognized as a supported file format."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ“œDATA DOWNLOAD SECTIONðŸ“œ**"
      ],
      "metadata": {
        "id": "I7d6uagHFbGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### APPEEAR LDDAC DATA DOWNLOAD"
      ],
      "metadata": {
        "id": "XsU-Aivn7ihA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=16IzXxuOv3jeoq6GLrPXJ4gJ0dag0PZ4i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4N7TJmtX7K4",
        "outputId": "2f03dceb-bcb8-4e76-b81d-ed7ccb6aa0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16IzXxuOv3jeoq6GLrPXJ4gJ0dag0PZ4i\n",
            "To: /content/url.txt\n",
            "\r  0% 0.00/2.33M [00:00<?, ?B/s]\r100% 2.33M/2.33M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/OUT/data/MOD09A1061/files\n",
        "!ls /content/drive/MyDrive/OUT/data/MOD09A1061/files\n",
        "%cd /content/drive/MyDrive/OUT/data/MOD09A1061/files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLh93IAEYs04",
        "outputId": "129b1711-5f17-4991-f456-8cb4b6ef9237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OUT/data/MOD09A1061/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### try download the list data"
      ],
      "metadata": {
        "id": "Iia9EHMD72b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --request POST --user kroy0001:/#j%kWrPA,8.HRe --header \"Content-Length: 0\" \"https://appeears.earthdatacloud.nasa.gov/api/login\""
      ],
      "metadata": {
        "id": "N7PNs-Mu9ibu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl -L -O --remote-header-name \\\n",
        "#   --header \"Authorization: Bearer bVVLVOIv29Lds-zADthteUE_1QlykgndjN5T6BaKMzMS-A11Z8UWtVsNbAJ85LWcGGerQH1KpM7eb-1KZS_Nig\" \\\n",
        "#   --location https://appeears.earthdatacloud.nasa.gov/api/bundle/908b9b61-5acf-48ca-933e-1fcd3b2704fc/c4d1addc-4e43-43e6-aac4-04cdcf04faca/MOD09A1.061_sur_refl_b01_doy2000129_aid0001.tif"
      ],
      "metadata": {
        "id": "IDFusRPU9up5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from multiprocessing import cpu_count\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from google.colab import output\n",
        "\n",
        "def download_url(url):\n",
        "    t0 = time.time()\n",
        "###########################################################################################################################\n",
        "    !curl -L -O --remote-header-name \\\n",
        "      --header \"Authorization: Bearer bVVLVOIv29Lds-zADthteUE_1QlykgndjN5T6BaKMzMS-A11Z8UWtVsNbAJ85LWcGGerQH1KpM7eb-1KZS_Nig\" \\\n",
        "      --location {url}\n",
        "###########################################################################################################################\n",
        "    return( time.time() - t0)\n",
        "        \n",
        "t0 = time.time()\n",
        "\n",
        "def download_parallel(args):\n",
        "    cpus = cpu_count()\n",
        "    results = ThreadPool(cpus - 1).imap_unordered(download_url, args)\n",
        "    for result in results:\n",
        "        print('time (s):', result)\n",
        "        output.clear()\n",
        "###########################################################################################################################\n",
        "file1 = open(\"/content/url.txt\", 'r')\n",
        "###########################################################################################################################\n",
        "download_parallel(file1)\n"
      ],
      "metadata": {
        "id": "rtfs6--L7RMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import output\n",
        "\n",
        "# file1 = open(\"/content/url.txt\", 'r')\n",
        "# link_list = [f for f in enumerate(file1)]\n",
        "# for i,link in enumerate(link_list):\n",
        "#     print(\"ok\")\n",
        "#     !curl -L -O --remote-header-name \\\n",
        "#     --header \"Authorization: Bearer bVVLVOIv29Lds-zADthteUE_1QlykgndjN5T6BaKMzMS-A11Z8UWtVsNbAJ85LWcGGerQH1KpM7eb-1KZS_Nig\" \\\n",
        "#     --location {link_list[i][1]}\n",
        "#     output.clear()\n"
      ],
      "metadata": {
        "id": "690P6zBI_OEb",
        "outputId": "5a39cfd9-bdc5-49d1-b6bf-f77756f053b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# backend test works"
      ],
      "metadata": {
        "id": "8hKAHlIZEYv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pathb2[25:25+10]   #file naming <<<<"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6_NO_NNYDJp0",
        "outputId": "df1abcdd-fb64-4e40-cc3c-6d28556f315a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'doy2000089'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m1 = !gdalinfo -json {temp_dir}\"BothCheck_result.tif\" | jq -r .geoTransform \n",
        "# coonstant_c = float(m1[2][9:9+16])*float(m1[6][9+1:9+16+1])*10000\n",
        "# print(str(coonstant_c*pixel_count_snow),str(coonstant_c*pixel_count_notsnow),str(coonstant_c*pixel_count_snow+coonstant_c*pixel_count_notsnow))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uFk-Ego40dt",
        "outputId": "b77b8504-ee2a-44f9-b731-0da12a6b5f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "snow: 16636  not snow: 46171\n",
            "2888.1944439222593 8015.798609661855 10903.993053584114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pathb2 = imgs_list_b2[5]\n",
        "# pathb4 = imgs_list_b4[5]\n",
        "# pathb6 = imgs_list_b6[5]\n",
        "# #creating file NDSI\n",
        "# !gdal_calc.py \\\n",
        "#   --overwrite \\\n",
        "#   --type=Float32 \\\n",
        "#   -A {image_dir}{pathb4} \\\n",
        "#   --A_band 1 \\\n",
        "#   -B {image_dir}{pathb6} \\\n",
        "#   --B_band 1 \\\n",
        "#   --outfile={temp_dir}\"NDSI_result.tif\" \\\n",
        "#   --calc=\"(A.astype(float) - B)/(A.astype(float) + B)\"\n",
        "\n",
        "# !gdal_calc.py \\\n",
        "#   --overwrite \\\n",
        "#   --type=Float32 \\\n",
        "#   -A {image_dir}{pathb2} \\\n",
        "#   --A_band 1 \\\n",
        "#   -B {temp_dir}\"NDSI_result.tif\" \\\n",
        "#   --B_band 1 \\\n",
        "#   --outfile={temp_dir}\"BothCheck_result.tif\" \\\n",
        "#   --calc=\"(B.astype(float)>=0.4)*(A.astype(float)>0.40*A.astype(float))\"#--calc=\"(A.astype(float)>0.011*A.astype(float))\"#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyJZfC6Y8Uxj",
        "outputId": "ee301f3d-0e93-4a8c-91e7-be6a1ffb3bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n",
            "0 .. 10 .. 20 .. 30 .. 40 .. 50 .. 60 .. 70 .. 80 .. 90 .. 100 - Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import pymodis\n",
        "# import gdalnumeric\n",
        "# #to clear output\n",
        "# from google.colab import output\n",
        "\n",
        "\n",
        "# image_dir = r'/content/drive/MyDrive/OUT/data/MOD09A1061/files/'\n",
        "# prefix = \"sur_refl_\"\n",
        "# bandend = [\"b01\", \"b02\", \"b03\", \"b04\", \"b05\", \"b06\", \"b07\", \"day_of_year\", \"qc_500m\", \"raz\", \"state_500m\", \"szen\", \"vzen\"]\n",
        "# DayOY = \"_doy\\d{7}_aid0001\"\n",
        "# fileExt = r'.tif'\n",
        "# temp_dir = r'/content/'\n",
        "# imgs_list = [f for f in os.listdir(image_dir) if f.endswith(fileExt)]\n",
        "# imgs_list.sort()\n",
        "# imgs_path = [os.path.join(image_dir, i) for i in imgs_list if i != 'outputs']\n",
        "# #creating a loop to run for all files in the directory having extension \".hdf\"\n",
        "# for name, image in enumerate(imgs_path):\n",
        "#   print('ok')\n",
        "#   print(name)\n",
        "#   print(image)\n",
        "#   path = imgs_list[name]\n",
        "#   #converting to sinusodial coordinate system to wgs 84 utm 43\n",
        "#   #import pymodis\n",
        "#   subset = [0,0,0,1,0,0,0]\n",
        "#   pymodis.convertmodis_gdal.convertModisGDAL( image_dir + path, temp_dir + path[:-4], subset, 2400,outformat=\"GTiff\",epsg=32643).run()\n",
        "  \n",
        "#   #cutting into Area Of interest using shape file\n",
        "#   !gdalwarp \\\n",
        "#   -cutline /content/beasBasinShapeFile.shp  -crop_to_cutline \\\n",
        "#   {temp_dir}{path[:-4]}\"_ndsi.tif\" \\\n",
        "#   {temp_dir}{path[:-4]}\"_ndsi_clipped.tif\"\n",
        "\n",
        "#   !rm -r {temp_dir}{path[:-4]}\"_ndsi.tif\"\n",
        "#   #deleting file\n",
        "\n",
        "#   #creating file NDSI>=0.4\n",
        "#   !gdal_calc.py \\\n",
        "#   -A {temp_dir}{path[:-4]}\"_ndsi_clipped.tif\" \\\n",
        "#   --outfile={temp_dir}{path[:-4]}\"_result.tif\" \\\n",
        "#   --calc=\"A/10>=40\"\n",
        "\n",
        "#   !rm -r {temp_dir}{path[:-4]}\"_ndsi_clipped.tif\"\n",
        "#   #deleting file\n",
        "\n",
        "#   #counting Snow and Non-Snowpixels  \n",
        "#   #import gdalnumeric\n",
        "#   raster_file = gdalnumeric.LoadFile(temp_dir + path[:-4]+\"_result.tif\")\n",
        "#   pixel_count_snow = (raster_file ==0).sum()\n",
        "#   pixel_count_notsnow = (raster_file ==1).sum()\n",
        "#   print(\"snow:\",pixel_count_snow,\" not snow:\",pixel_count_notsnow)\n",
        "\n",
        "#   #creating constant for multiplication at pixel size with count of pixels\n",
        "#   m1 = !gdalinfo -json {temp_dir}{path[:-4]}\"_result.tif\" | jq -r .geoTransform \n",
        "#   coonstant_c = int(m1[2][9:9+4])*int(m1[6][9+1:9+4+1])/1000000\n",
        "\n",
        "#   !rm -r {temp_dir}{path[:-4]}\"_result.tif\"\n",
        "#   #deleting file\n",
        "\n",
        "#   #combining name of the  file , SnowCoverArea , NonSnowCoverArea to a text file format\n",
        "#   lines = str(path[8:8+8] + \",\" + str(coonstant_c*pixel_count_snow) + \",\" + str(coonstant_c*pixel_count_notsnow))\n",
        "#   with open(temp_dir + \"out.txt\", \"a+\", encoding = \"utf-8\") as f:\n",
        "#     f.writelines('\\n' + lines)\n",
        "#     output.clear() #to_clear_the_output_console_everytime"
      ],
      "metadata": {
        "id": "ioDVU1ltWkZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}