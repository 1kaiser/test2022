{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHIRPS_CLIP_by_shapefile.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9mwiTpHinFii7IvxMrLBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2022/blob/main/CHIRPS_CLIP_by_shapefile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install wget"
      ],
      "metadata": {
        "id": "YYSjS-VyLZo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "pwd = os.getcwd()\n",
        "print(pwd)"
      ],
      "metadata": {
        "id": "OxCCETKELRba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAgxfZ8VIcVb"
      },
      "outputs": [],
      "source": [
        "os.chdir(pwd)\n",
        "\n",
        "import wget\n",
        "start_year = 1981 #yyyy\n",
        "end_year = 2022 #yyyy\n",
        "\n",
        "\n",
        "path = \"../\"\n",
        "download_dir = os.path.join(path,\"CHIRPS_Rainfall_Global\")\n",
        "if not os.path.exists(download_dir):\n",
        "    os.mkdirs(download_dir)\n",
        "\n",
        "base_site = \"https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/\"\n",
        "\n",
        "for year in range(start_year,end_year+1,1):\n",
        "    file_start_name = \"chirps-v2.0.\"\n",
        "    file_end_name = \".days_p05\"\n",
        "    file_ext_name = \".nc\"\n",
        "    file_name = \"{}{}{}{}\".format{file_start_name,year,file_end_name,file_ext_name}\n",
        "    url = \"{}/{}\".format(base_site,file_name)\n",
        "    print(\"{}{}\".format(\"\\nDownloading.....\",file_name))\n",
        "    wget.download(url,download_dir)\n",
        "    print(\"{}{}\".format(file_name,\" Downloaded Successfully!\"))\n",
        "print(\"\\nAll data HAve Been Downloaded Successfully!\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# processing extraction of required variables fro the netCDF files"
      ],
      "metadata": {
        "id": "q-okmo7eLzzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install netCDF4"
      ],
      "metadata": {
        "id": "ve8y4JVsLKNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from netCDF4 import Dataset\n",
        "import pandas as pd\n",
        "from datetime import datetime,timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "oTu8Ydz_LOZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(\"../CHIRPS_Rainfall_Global/chirps-v2.0.1992.days_p05.nc\",\"r\")\n",
        "print(\"here are all the variables of your data\")\n",
        "print(data.variable.keys())"
      ],
      "metadata": {
        "id": "zbAj8doBNCIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "p4DpUWdSNZ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = data.variables['precip']\n",
        "tp"
      ],
      "metadata": {
        "id": "ajU9C4alNv-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unitp = data.variables['precip'].units\n",
        "unitp"
      ],
      "metadata": {
        "id": "2VJBd-DMN4Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lats = data.variables['latitude']\n",
        "lats"
      ],
      "metadata": {
        "id": "BPKp5ROCOLQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lats = data.variables['latitude'][:]#gives all lattitudes data\n",
        "lats\n",
        "lons = data.variables['longitude'][:]\n",
        "lons\n",
        "times = data.variables['time']\n",
        "times\n",
        "times = data.variables['time'][:10] #first 10 time steps\n",
        "times\n",
        "unitt = data.variables['time'].units #take unit of time variables\n",
        "unitt"
      ],
      "metadata": {
        "id": "7dlMdK3EOCTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the data in dayly intervals\n",
        "tp = data.variables['precip'][:]\n",
        "unitp = data.variables['precip'].units\n",
        "unitt = data.variables['time'].units #take unit of time variables\n",
        "times = data.variables['time'][:]\n",
        "lats = data.variables['latitude'][:]#gives all lattitudes data\n",
        "lons = data.variables['longitude'][:]"
      ],
      "metadata": {
        "id": "Om1RMVwtPOCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlp_toolkits.basemap import Basemap\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "\n",
        "map = Basemap(projection = 'null',\n",
        "              llcrnrlat = -50,\n",
        "              urcrnrlat = 50,\n",
        "              llcrnelon = -180,\n",
        "              urcrnrlon = 180,\n",
        "              resolution = 'c')"
      ],
      "metadata": {
        "id": "xY_SaTRVUmVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map.drawcoastlines()\n",
        "map.drawcountries(colour='red')\n",
        "map.drawstates(colour='blue')\n",
        "map.drawcountries(colour='orange')\n",
        "map.drawrivers(colour='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s6VKOa-iV0We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map.drawcoastlines()\n",
        "map.drawstates()\n",
        "map.drawcountries()\n",
        "map.drawmasks(land_colour='linen', ocean_color='#CCFFFF')\n",
        "map.drawcountries()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dLL3Qd4xWaav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lons, lats = np.meshgrid(lon, lat)\n",
        "x, y = map(lons, lats)"
      ],
      "metadata": {
        "id": "rDv2iQkAW1gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precip = map.contourf(x,y,tp[5,:,:])\n",
        "cb = map.colorbar(precip,\"bottom\", size=\"5%\", pad=\"2%\")\n",
        "plt.title('Daily Precipitation')\n",
        "cb.set_label('Rainfall ({})'.format(unitp))"
      ],
      "metadata": {
        "id": "OhN4lj8fXAj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "making subset of the complete data for computation"
      ],
      "metadata": {
        "id": "ZQqlHCs4Xunl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(pwd)\n",
        "import os, sys\n",
        "from netCDF4 import Dataset\n",
        "import xarray as xr\n",
        "from numpy import *\n",
        "import time\n",
        "from datetime import date\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filter warnings ('ignore')\n",
        "path \"C:/Users/mxr8032/Downloads/CHIRPS/\"\n",
        "output_dir = os.path.join (path, \"CHIRPS_Rainfaff_India\")\n",
        "if not os.path.exists(output_dir): \n",
        "  os.makedirs(output_dir)\n",
        "input_dir = os.path.join(path, \"CHIRPS_Rainfaff_Global\")\n",
        "latbound = [0,40]\n",
        "longbound [65,100]\n",
        "\n",
        "os.chdir(input_dir)\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.nc'):\n",
        "      file_name, file_ext = os.path.splitext(filename)\n",
        "      new_filename = \"{}_{}{}\".format(file_name,'India',file_ext)\n",
        "      name_ncfile = \"{}_{}{}\".format(output_dir,'India',new_filename)\n",
        "      print(\"Noe reading {}\".format(filename))\n",
        "      data = Dataset(filename,'r')\n",
        "      print('\\nReading data from the main NetCDF file !')\n",
        "\n",
        "\n",
        "      times = data.variables['time'][:]\n",
        "      lats = data.variables['latitude'][:]#gives all lattitudes data\n",
        "      lons = data.variables['longitude'][:]\n",
        "      print(\"\\n Reading Completed!\")\n",
        "\n",
        "      lat_lb = argmin(abs(lats-latbound[0]))\n",
        "      lat_ub = argmin(abs(lats-latbound[1]))\n",
        "      lon_lb = argmin(abs(lons-longbound[0]))\n",
        "      lon_ub = argmin(abs(lons-longbound[1]))\n",
        "\n",
        "      print('\\n reading the variables values only between the range of the bounding box ! ')\n",
        "      lat_sub = data.variable['latitude'][lat_lb:lat:ub]\n",
        "      lon_sub = data.variable['latitude'][lon_lb:lon:ub]\n",
        "      print('\\n Reading complete ! ')\n",
        "\n",
        "      my_file = Dataset(new_file, 'w', format = 'NETCDF4')\n",
        "      my_file.Conventions = data.Conventions\n",
        "      my_file.title = data.title\n",
        "      my_file.history = data.history\n",
        "      my_file.version = data.version\n",
        "      my_file.date_created = data.date_created\n",
        "      my_file.creator_name = data.creator_name\n",
        "      my_file.creator_email = data.creator_email\n",
        "      my_file.institution = data.institution\n",
        "      my_file.documentation = data.documentation\n",
        "      my_file.creator_name = data.creator_name\n",
        "      my_file.date_created = data.date_created\n",
        "      my_file.documentation = data.documentation\n",
        "      my_file.date_subsetted = str(date.today ()) #time.ctime (time.time()) \n",
        "      my_file.subsetter_name = 'Md Arifur Rahman, UT Arlington, Tx, USA'\n",
        "      my_file.discription = 'Data Subsetted on: ' + str(date.today ())\n",
        "      my_file.reference = data.reference\n",
        "      my_file.comments = data.comments\n",
        "      my_file.acknowledgements = data. acknowledgements\n",
        "      my_file.ftp_url = data.ftp_url    \n",
        "      my_file.faq = data.faq print (\"\\nSuccessfully created new NetCDF File in the output directory!\n",
        "\n",
        "# Creating the Dimensions of new variables\n",
        "\n",
        "      print (\"\\nCreating Dimensions of new variables!\")\n",
        "      ldim = abs(lat_lb-lat_ub) # getting the no of element\n",
        "      Indim = abs(lon_ub-lon_lb)\n",
        "      tdim = len(tims)\n",
        "      longitude = my_file.createDimension ('longitude', Indim) \n",
        "      latitude = my_file.createDimension ('latitude', ldim)\n",
        "      time = my_file.createDimension ('time', tdim)\n",
        "      #my_file.createDimension ('longitude', Indim)\n",
        "      #my_file.createDimension ('latitude', ldim) #my_file.createDimension ('time', None)\n",
        "      print (\"\\nDone!!!\")   \n",
        "\n",
        "      lat = my_file.createVariable ('latitude', float32, ('latitude',)) \n",
        "      lat.units = data.variables['latitude'].units\n",
        "      lat.standard_name = data.variables['latitude'].standard_name\n",
        "      lat.long_name = data.variables['latitude'].long_name\n",
        "      lat.axis = data.variables['latitude'].axis\n",
        "\n",
        "      lon = my_file.createVariable ('longitude', float32, ('longitude',)) \n",
        "      lon.units = data.variables['longitude'].units\n",
        "      lon.standard_name = data.variables['longitude'].standard_name\n",
        "      lon.long_name = data.variables['longitude'].long_name\n",
        "      lon.axis = data.variables['longitude'].axis\n",
        "\n",
        "      tp = my_file.createVariable ('precip', float32, ('time','lattitude','longitude',),fill_value = -9999.0) \n",
        "      tp.units = data.variables['precip'].units\n",
        "      tp.standard_name = data.variables['precip'].standard_name\n",
        "      tp.long_name = data.variables['precip'].long_name\n",
        "      tp.time_step = data.variables['precip'].time_step\n",
        "\n",
        "      tp.geoststial_lat_min = 0.0\n",
        "      tp.geoststial_lat_max = 40.0\n",
        "      tp.geoststial_lon_min = 50.0\n",
        "      tp.geoststial_lon_max = 110.0\n",
        "\n",
        "      times = my_file.createVariable ('time', float32, ('time',))\n",
        "      times.units = data.variables['time'].units\n",
        "      times.standard_name = data.variables['time'].standard_name\n",
        "      times.calendar = data.variables['time'].calendar\n",
        "      times.axis = data.variables['time'].axis\n",
        "\n",
        "      print(\"\\n Successfully Created the Variables of new NetCDF file!\")\n",
        "      lat[:] = lat_sub\n",
        "      lon[:] = lon_sub\n",
        "      times[:] = tims\n",
        "      tp[:,:,:] = data.variables['precip'][:,lat_lb:lat_ub,lon_lb:lon_ub]\n",
        "      print(\"closing the files and clearing the memory\")\n",
        "      data.close()\n",
        "      my_file.close()\n",
        "      del data\n",
        "      del my_file\n",
        "      del tp\n",
        "      gc.collect()\n",
        "      print(\"memory cleared\")\n",
        "print(\"\\n\")\n",
        "print('!!!!!!!!!!!!!!!!!!!!!')\n",
        "print('!!!subsetting done!!!')\n",
        "print('!!!!!!!!!!!!!!!!!!!!!')\n"
      ],
      "metadata": {
        "id": "zrpWyWnoXzv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clipping The NetCDF Files by Shapefiles"
      ],
      "metadata": {
        "id": "AJhQGl3TikBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import regionmask\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import cartopy.crs as ccrs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "10 %matplotlib inline"
      ],
      "metadata": {
        "id": "tr6WKRLLhxI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "take location of shape file from uploaded file folder after the file has been uploaded its expenstion is `*.shp` file"
      ],
      "metadata": {
        "id": "whLRLX6YjAjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shapefile = \"\"\n",
        "baseShape = gpd.read_file(shapefile)\n",
        "baseshape\n",
        "\n",
        "#baseshape = gpD.read_file(shapefile)\n",
        "#display(baseshape)\n",
        "#lon = np.arange(-180, 180)\n",
        "#lat = np.arange(-90, 90)\n",
        "#mask = regionmask.mask_geopandas(baseshape, lon, lat)\n",
        "#f, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
        "#mask.plot(\n",
        "#     ax=ax,\n",
        "#     transform=ccrs.PlateCarree(),\n",
        "#     add_colorbar=False,\n",
        "# )\n",
        "# ax.coastlines(color=\"0.1\");"
      ],
      "metadata": {
        "id": "v_GbNCjLi2CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (16,10))\n",
        "baseshape.plot(ax = ax, column = 'NAME_ISO')"
      ],
      "metadata": {
        "id": "3izCBrgEjWDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = list(baseshape['ISO'])\n",
        "my_list_unique = set(list(baseshape['ISO']))\n",
        "indexes = [my_list.index(x) for x in my_list_unique]"
      ],
      "metadata": {
        "id": "hHk6sXdqj8z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseshape_mask_poly = regionmask.Regions_cls(name = 'NAME_ISO', numbers = indexes, names = baseshape.NAME_ISO[indexes])\n",
        "baseshape_mask_poly"
      ],
      "metadata": {
        "id": "MTKBL2SfkiXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = xr.open_dataarray(\"../*.nc\")\n",
        "ds"
      ],
      "metadata": {
        "id": "0_4bK3U2ogSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = baseshape_mask_poly.mask(ds.isel(time=0),lat_name='latitude', lon_name='longitude')\n",
        "mask #lat lon is taken from \"ds\" dataset"
      ],
      "metadata": {
        "id": "WmZWDTToowaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the file as its better to save for future use as computaion cost is high to generete everyy time new masks\n",
        "mask.to_netcdf('../mask....*.nc')"
      ],
      "metadata": {
        "id": "6_PochbNpGvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = xr.open_dtaarray('../mask....*.nc')\n",
        "mask"
      ],
      "metadata": {
        "id": "qv9vw1LGpbRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_shape = ds.where(mask == 0)\n",
        "masked_shape #gives reading where ds value is 0 i..e inside the region of mask it will read the ds dataset"
      ],
      "metadata": {
        "id": "kLPxvkzbptHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,8))\n",
        "ax = plt.axes()\n",
        "masked_shape.isel(time = 0).plot(ax = ax) # time <<< value day of the year 250 >>. september   360 >>. december soo on \n",
        "baseshape.plot(ax = ax, alpha = 0.8, facecolor= 'none')"
      ],
      "metadata": {
        "id": "OaZkddHpp2f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latitude = 25.\n",
        "longitude = 80.\n",
        "data = masked_shape.sel(longitude= longitude, latitude=latitude, method='nearest')\n",
        "data"
      ],
      "metadata": {
        "id": "tOtwjVuNvOWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataframe from xarray\n",
        "df = data.to_dataframe()\n",
        "fig = plt.figure(figsize=(16,8))\n",
        "df['precip'].plot()"
      ],
      "metadata": {
        "id": "vspdZ-AYvkkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot of monthly rainfall distribution overindia\n",
        "df['month'] = df.index.strftime(\"%b\")\n",
        "df"
      ],
      "metadata": {
        "id": "UVksOSmfv5sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "as = plt.axes()\n",
        "sns.boxplot(x=\"month\",y=\"prepip\",data=df, plette=\"set1\")\n",
        "figure = ax.get_figure()\n",
        "figure.set_size_inches(12,8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GrcZgE4ZwQ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Js0TsY_K5aYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving the masjked data inside the region of shape file "
      ],
      "metadata": {
        "id": "ctBFlny55biX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = {\"precip\": {'zlib': True,\"complevel\":4}} # 1 to 9 >> complevel\n",
        "masked_shape.to_netcdf('../india.nc',mode='w',format='NETCDF4', engine='netcdf4', encoding = encoding)"
      ],
      "metadata": {
        "id": "pLAQUJ8yyU87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = xr.open_dataarray('../india.nc')\n",
        "data"
      ],
      "metadata": {
        "id": "hHL8I7E84tZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_point = data.sel(latitude=25, longitude=80, method = 'nearest')\n",
        "single_point.plot()\n"
      ],
      "metadata": {
        "id": "VAvthQXd42mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isel(time=250).plot(robust=True)"
      ],
      "metadata": {
        "id": "m11r9uNU5GjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# everything all together "
      ],
      "metadata": {
        "id": "c-xeCzAh6Dyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir (pwd)\n",
        "import os, sys\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import regionmask\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings; warnings.filterwarnings (action='ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "path = \"C:/Users/mxr8032/Downloads/CHIRPS/\"\n",
        "input_dir = os.path.join (path, \"CHIRPS_Rainfall_India\")\n",
        "output_dir = os.path.join (path, \"CHIRPS_India_Masked\")\n",
        "if not os.path. exists (output_dir):\n",
        "    os.makedirs (output_dir)\n",
        "\n",
        "shapefile = \"C:/Users/mxr8032/Downloads/CHIRPS/India_Shapefile/IND_adm0.shp\"\n",
        "countries = gpd.read_file (shapefile)\n",
        "#countries\n",
        "my_list = list(countries['ISO'])\n",
        "my_list_unique = set(list(countries ['ISO']))\n",
        "indexes = [my_list.index (x) for x in my_list_unique]\n",
        "countries_mask_poly = regionmask. Regions_cls (name = 'NAME_ISO', numbers = indexes, ames = countries.NAME_ISO[indexes])\n",
        "#countries_mask_poly\n",
        "# Plotting the shapefile to observe the extent of the clip\n",
        "print(\"Here is the map of the shapefile of {}\".format (countries_mask_poly.names[0]))\n",
        "fig, ax = plt.subplots (figsize=(16,10))\n",
        "countries.plot (ax=ax, column = 'NAME_ISO')\n",
        "#mask= countries_mask_poly.mask (ds.isel (time = 0), lat name='latitude', lon name='ld\n",
        "mask = xr.open_dataarray('../mask_by_India.nc')\n",
        "\n",
        "os.chdir (input_dir)\n",
        "for filename in os.listdir():\n",
        "  if filename.endswith('.nc'): \n",
        "    file_name, file_ext = os.path.splitext(filename)\n",
        "    # chirps-v2.0.1981.days_p05_Indip.nc\n",
        "    chirps, op, year, days = file_name.split(\".\")\n",
        "    new_filename = \"{}_{}{}\".format(year, chirps, file_ext)\n",
        "    #print (new_filename)\n",
        "    new_ncfile= \"{}/{}\".format(output_dir, new_filename)\n",
        "    #print (new_ncfile)\n",
        "    print (\"Now Reading {}\".format(filename)) \n",
        "    ds = xr.open_dataarray(filename)\n",
        "    #masking the netcdf file based on the shapefile\n",
        "    print (\"Now Applying the NetCDF Mask For Year (}\".format (int (year))) print (\"\\nPlease Wait ...... It Will Take a While!\")\n",
        "    masked shape = ds.where(mask == 0)\n",
        "    masked_shape\n",
        "    print (\"Masking is Successfull! Saving the data as .nc file after plotting\")\n",
        "    #plotting the masked data\n",
        "    plt.figure(figsize=(16,10))\n",
        "    ax = plt.axes()\n",
        "    masked_shape.isel(time=245).plot(ax=ax)\n",
        "    countries.plot(ax=ax, alpha = 0.8, facecolor ='none')\n",
        "    #writing the masked netcdf file to output directory\n",
        "    encoding = {\"precip\": {'zlib': True,\"complevel\":4}} # 1 to 9 >> complevel\n",
        "    masked_shape.to_netcdf(new_ncfile,mode='w',format='NETCDF4', engine='netcdf4', encoding = encoding)\n",
        "    print(\"saved the file Successsfully as {}\".format(new_filename))\n",
        "    print(\"\\n\")\n",
        "    del ds\n",
        "    gc.collect()\n",
        "    print(\"memory cleared\")\n",
        "print(\"\\n\")\n",
        "print('!!!!!!!!!!!!!!!!!!!!!')\n",
        "print('!!!subsetting done!!!')\n",
        "print('!!!!!!!!!!!!!!!!!!!!!')"
      ],
      "metadata": {
        "id": "p4_zRPNf6IOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}