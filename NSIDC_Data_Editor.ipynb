{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2022/blob/main/NSIDC_Data_Editor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tR28xKL2xHV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ng_wcRuL252M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c6b19d-9040-4abf-cc10-03fcd241c567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NbFxO-hu1Tx"
      },
      "source": [
        "# VIEW FIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sUj_Ezpy3CY"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/OUT/data/MOD10A1v6/MOD10A1.A2000055.h24v05.006.2016061160550.hdf /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p3DCyp74URzd",
        "outputId": "b0dd7dee-ec4e-41d6-a6ac-12bd76a821bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Driver: HDF4/Hierarchical Data Format Release 4\n",
            "Files: /content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\n",
            "Size is 512, 512\n",
            "Coordinate System is `'\n",
            "Metadata:\n",
            "  ASSOCIATEDINSTRUMENTSHORTNAME.1=MODIS\n",
            "  ASSOCIATEDPLATFORMSHORTNAME.1=Terra\n",
            "  ASSOCIATEDSENSORSHORTNAME.1=MODIS\n",
            "  DAYNIGHTFLAG=Day\n",
            "  DESCRREVISION=6.1\n",
            "  Discarded packets=0\n",
            "  EASTBOUNDINGCOORDINATE=101.442329056026\n",
            "  EQUATORCROSSINGDATE.1=2021-07-25\n",
            "  EQUATORCROSSINGLONGITUDE.1=76.1767704977868\n",
            "  EQUATORCROSSINGTIME.1=05:22:31.564707\n",
            "  EXCLUSIONGRINGFLAG.1=N\n",
            "  GRANULENUMBER=64\n",
            "  GRINGPOINTLATITUDE.1=46.439029105208, 42.258061555647, 24.9935514690836, 28.1641925698701\n",
            "  GRINGPOINTLONGITUDE.1=72.2615397346004, 101.445417268375, 93.9451458044932, 70.4819136712824\n",
            "  GRINGPOINTSEQUENCENO.1=1, 2, 3, 4\n",
            "  identifier_product_doi=10.5067/MODIS/MOD01.061\n",
            "  identifier_product_doi=10.5067/MODIS/MOD01.061\n",
            "  identifier_product_doi_authority=http://dx.doi.org\n",
            "  identifier_product_doi_authority=http://dx.doi.org\n",
            "  Incomplete Scans=0\n",
            "  INPUTPOINTER=ENG_DATA_LIST_TERRA_V6.1.5, MOD00F.A2021206.0505.20212060457.001.PDS\n",
            "  LOCALGRANULEID=MOD01.A2021206.0510.061.2021217151715.hdf\n",
            "  LOCALVERSIONID=6.0.0\n",
            "  LONGNAME=MODIS/Terra Raw Radiances in Counts 5-Min L1A Swath\n",
            "  Max BB Frames=50\n",
            "  Max Earth Frames=1354\n",
            "  Max SD Frames=50\n",
            "  Max SRCA Frames=10\n",
            "  Max SV Frames=50\n",
            "  Max Total Frames=1514\n",
            "  Missing Packets=0\n",
            "  NORTHBOUNDINGCOORDINATE=46.4176312867238\n",
            "  Number of Day mode scans=203\n",
            "  Number of Night mode scans=0\n",
            "  Number of Scans=203\n",
            "  ORBITNUMBER.1=114896\n",
            "  Packets with bad CRC=0\n",
            "  PGEVERSION=6.1.5\n",
            "  PROCESSINGENVIRONMENT=Linux minion7590 3.10.0-1160.36.2.el7.x86_64 #1 SMP Wed Jul 21 11:57:15 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\n",
            "  PROCESSVERSION=6.0.6\n",
            "  PRODUCTIONDATETIME=2021-08-05T15:18:05.000Z\n",
            "  PRODUCTIONHISTORY=PGE01:6.1.5\n",
            "  RANGEBEGINNINGDATE=2021-07-25\n",
            "  RANGEBEGINNINGTIME=05:10:00.000000\n",
            "  RANGEENDINGDATE=2021-07-25\n",
            "  RANGEENDINGTIME=05:15:00.000000\n",
            "  REPROCESSINGACTUAL=reprocessed\n",
            "  REPROCESSINGPLANNED=further update is anticipated\n",
            "  Scan Types in product=Day\n",
            "  SHORTNAME=MOD01\n",
            "  SOUTHBOUNDINGCOORDINATE=25.0716791313738\n",
            "  VERSIONID=61\n",
            "  WESTBOUNDINGCOORDINATE=70.5041299066153\n",
            "Subdatasets:\n",
            "  SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":1\n",
            "  SUBDATASET_1_DESC=[208x6] Frame count array (16-bit integer)\n",
            "  SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":2\n",
            "  SUBDATASET_2_DESC=[208x10] Scan Type (8-bit character)\n",
            "  SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":10\n",
            "  SUBDATASET_3_DESC=[208x3] CCSDS Application Identifiers (16-bit integer)\n",
            "  SUBDATASET_4_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":13\n",
            "  SUBDATASET_4_DESC=[208x4] Scan quality array (32-bit integer)\n",
            "  SUBDATASET_5_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":14\n",
            "  SUBDATASET_5_DESC=[208x64x2] SD sector Pixel quality (16-bit integer)\n",
            "  SUBDATASET_6_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":15\n",
            "  SUBDATASET_6_DESC=[208x64x2] SRCA sector Pixel quality (16-bit integer)\n",
            "  SUBDATASET_7_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":16\n",
            "  SUBDATASET_7_DESC=[208x64x2] BB sector Pixel quality (16-bit integer)\n",
            "  SUBDATASET_8_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":17\n",
            "  SUBDATASET_8_DESC=[208x64x2] SV sector Pixel quality (16-bit integer)\n",
            "  SUBDATASET_9_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":18\n",
            "  SUBDATASET_9_DESC=[208x1400x2] Earth sector Pixel quality (16-bit integer)\n",
            "  SUBDATASET_10_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":19\n",
            "  SUBDATASET_10_DESC=[8320x2x256] SD_250m (16-bit integer)\n",
            "  SUBDATASET_11_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":20\n",
            "  SUBDATASET_11_DESC=[4160x5x128] SD_500m (16-bit integer)\n",
            "  SUBDATASET_12_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":21\n",
            "  SUBDATASET_12_DESC=[2080x14x64] SD_1km_day (16-bit integer)\n",
            "  SUBDATASET_13_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":22\n",
            "  SUBDATASET_13_DESC=[2080x17x64] SD_1km_night (16-bit integer)\n",
            "  SUBDATASET_14_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":23\n",
            "  SUBDATASET_14_DESC=[8320x2x256] SRCA_250m (16-bit integer)\n",
            "  SUBDATASET_15_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":24\n",
            "  SUBDATASET_15_DESC=[4160x5x128] SRCA_500m (16-bit integer)\n",
            "  SUBDATASET_16_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":25\n",
            "  SUBDATASET_16_DESC=[2080x14x64] SRCA_1km_day (16-bit integer)\n",
            "  SUBDATASET_17_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":26\n",
            "  SUBDATASET_17_DESC=[2080x17x64] SRCA_1km_night (16-bit integer)\n",
            "  SUBDATASET_18_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":27\n",
            "  SUBDATASET_18_DESC=[8320x2x256] BB_250m (16-bit integer)\n",
            "  SUBDATASET_19_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":28\n",
            "  SUBDATASET_19_DESC=[4160x5x128] BB_500m (16-bit integer)\n",
            "  SUBDATASET_20_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":29\n",
            "  SUBDATASET_20_DESC=[2080x14x64] BB_1km_day (16-bit integer)\n",
            "  SUBDATASET_21_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":30\n",
            "  SUBDATASET_21_DESC=[2080x17x64] BB_1km_night (16-bit integer)\n",
            "  SUBDATASET_22_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":31\n",
            "  SUBDATASET_22_DESC=[8320x2x256] SV_250m (16-bit integer)\n",
            "  SUBDATASET_23_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":32\n",
            "  SUBDATASET_23_DESC=[4160x5x128] SV_500m (16-bit integer)\n",
            "  SUBDATASET_24_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":33\n",
            "  SUBDATASET_24_DESC=[2080x14x64] SV_1km_day (16-bit integer)\n",
            "  SUBDATASET_25_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":34\n",
            "  SUBDATASET_25_DESC=[2080x17x64] SV_1km_night (16-bit integer)\n",
            "  SUBDATASET_26_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":35\n",
            "  SUBDATASET_26_DESC=[8320x2x5600] EV_250m (16-bit integer)\n",
            "  SUBDATASET_27_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":36\n",
            "  SUBDATASET_27_DESC=[4160x5x2800] EV_500m (16-bit integer)\n",
            "  SUBDATASET_28_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":37\n",
            "  SUBDATASET_28_DESC=[2080x14x1400] EV_1km_day (16-bit integer)\n",
            "  SUBDATASET_29_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":38\n",
            "  SUBDATASET_29_DESC=[2080x17x1400] EV_1km_night (16-bit integer)\n",
            "  SUBDATASET_30_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":39\n",
            "  SUBDATASET_30_DESC=[208x10] fpa_aem_config (8-bit integer)\n",
            "  SUBDATASET_31_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":42\n",
            "  SUBDATASET_31_DESC=[208x550] fpa_dcr_offset (8-bit integer)\n",
            "  SUBDATASET_32_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":43\n",
            "  SUBDATASET_32_DESC=[208x78] raw_mir_enc (16-bit integer)\n",
            "  SUBDATASET_33_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":44\n",
            "  SUBDATASET_33_DESC=[208x40] raw_vs_def (16-bit integer)\n",
            "  SUBDATASET_34_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":45\n",
            "  SUBDATASET_34_DESC=[208x24] raw_vs_act (16-bit integer)\n",
            "  SUBDATASET_35_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":46\n",
            "  SUBDATASET_35_DESC=[208x224] raw_sci_eng (8-bit integer)\n",
            "  SUBDATASET_36_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":47\n",
            "  SUBDATASET_36_DESC=[208x128] raw_hk_telem (8-bit integer)\n",
            "  SUBDATASET_37_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":48\n",
            "  SUBDATASET_37_DESC=[208x64] raw_sc_ancil (16-bit integer)\n",
            "  SUBDATASET_38_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":49\n",
            "  SUBDATASET_38_DESC=[208x40] raw_param (8-bit integer)\n",
            "  SUBDATASET_39_NAME=HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":50\n",
            "  SUBDATASET_39_DESC=[208x550] raw_pv_gains (8-bit integer)\n",
            "Corner Coordinates:\n",
            "Upper Left  (    0.0,    0.0)\n",
            "Lower Left  (    0.0,  512.0)\n",
            "Upper Right (  512.0,    0.0)\n",
            "Lower Right (  512.0,  512.0)\n",
            "Center      (  256.0,  256.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Default title text { vertical-output: true }\n",
        "path = \"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\" #@param {type:\"string\"}\n",
        "%cd /content\n",
        "!gdalinfo {path}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdal_translate \\\n",
        "  HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":13 \\\n",
        "  /content/MOD10A1vv.tif"
      ],
      "metadata": {
        "id": "4Ovv6ZM07_Bh",
        "outputId": "ef130f52-f8f6-4a06-9e12-acebd2c1f425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input file size is 4, 208\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdaltransform -s_srs EPSG:6842 -t_srs WGS84 {path} {path}\n",
        "#!gdalwarp -t_srs \"+proj=longlat +datum=WGS84 +no_defs\" {path} reproj_vel_mosaic.tif"
      ],
      "metadata": {
        "id": "OY03pomN7bcJ",
        "outputId": "63c3f983-0f6b-4482-95a2-532cf3e63d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR 1: The transformation is already \"north up\" or a transformation between pixel/line and georeferenced coordinates cannot be computed for /content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf. There is no affine transformation and no GCPs. Specify transformation option SRC_METHOD=NO_GEOTRANSFORM to bypass this check.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyModis"
      ],
      "metadata": {
        "id": "70TAh20JybZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymodis\n",
        "subset = [0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "pymodis.convertmodis_gdal.convertModisGDAL(path,path[:-4],subset,2400,outformat=\"GTiff\",epsg=32643).run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "xjHlV0o_ygp9",
        "outputId": "49bb5ca7-9551-4b3f-c49f-4207d08f28ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a1e5de08fb63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymodis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpymodis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvertmodis_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvertModisGDAL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GTiff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32643\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymodis/convertmodis_gdal.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, quiet)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createWarped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymodis/convertmodis_gdal.py\u001b[0m in \u001b[0;36m_createWarped\u001b[0;34m(self, raster)\u001b[0m\n\u001b[1;32m    196\u001b[0m         tmp_ds = gdal.AutoCreateWarpedVRT(src, src.GetProjection(),\n\u001b[1;32m    197\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst_wkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                                           self.error_threshold)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mAutoCreateWarpedVRT\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAutoCreateWarpedVRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m     \u001b[0;34m\"\"\"AutoCreateWarpedVRT(Dataset src_ds, char const * src_wkt=None, char const * dst_wkt=None, GDALResampleAlg eResampleAlg, double maxerror=0.0) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoCreateWarpedVRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCreatePansharpenedVRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The transformation is already \"north up\" or a transformation between pixel/line and georeferenced coordinates cannot be computed for HDF4_SDS:UNKNOWN:\"/content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\":1. There is no affine transformation and no GCPs. Specify transformation option SRC_METHOD=NO_GEOTRANSFORM to bypass this check."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdalwarp -cutline /content/beasBasinShapeFile.shp  -crop_to_cutline /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif /content/clip_ndsi-snow-cover.tif"
      ],
      "metadata": {
        "id": "-K06H9lwDdV8",
        "outputId": "20163415-5e3b-454d-9286-9d200a31762e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output file that is 74P x 45L.\n",
            "Processing input file /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif.\n",
            "Using internal nodata values (e.g. 255) for image /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif.\n",
            "Copying nodata values from source /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif to destination /content/clip_ndsi-snow-cover.tif.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import gdalnumeric\n",
        "path = ('dir')\n",
        "os.chdir(path)\n",
        "for rasters in os.listdir(path):\n",
        "    raster_file = gdalnumeric.LoadFile(rasters)\n",
        "    pixel_count_snow = ((raster_file <=0) + (raster_file >= 25)).sum()\n",
        "    pixel_count_notsnow = ((raster_file <=0) + (raster_file >= 25)).sum()\n",
        "    print(\"snow:\",pixel_count_snow,\" not snow:\",pixel_count_notsnow)"
      ],
      "metadata": {
        "id": "pR8oqMAvekDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdalinfo /content/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf"
      ],
      "metadata": {
        "id": "GQ0jZijluqKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gdal_calc.py \n",
        "!gdal_calc.py \\\n",
        "  -A {path} \\\n",
        "  --A_band=4 \\\n",
        "  -B {path} \\\n",
        "  --B_band=6 \\\n",
        "  --outfile=result.tif \\\n",
        "  --calc=\"(A-B)/(A+B)\""
      ],
      "metadata": {
        "id": "Pay1nAsOfsrq",
        "outputId": "ae2742f7-f81a-4544-8c8d-c7cf6d457415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR 4: path: No such file or directory\n",
            "No such file or directory: 'path'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -e robots=off -m -np -R .html,.tmp -nH --cut-dirs=3 \\\n",
        "  \"https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/61/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\" \\\n",
        "  --header \"Authorization: Bearer a3JveTAwMDE6YzJOb2JHSnZlVEkyUUdkdFlXbHNMbU52YlE9PToxNjYwMDU0MjQ1OmM3NjNmMmI0ODdiNDY3M2YwZmM0OWM0MGM1ODhhNmM2NzNkYmNhZmM\" \\\n",
        "  -P .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CANw1lUKFYhn",
        "outputId": "80833fbc-7d04-4d4d-c9f6-c23be81b78b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "504 Gateway Time-out\n",
            "Retrying.\n",
            "\n",
            "--2022-08-09 16:46:59--  (try: 4)  https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/61/MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf\n",
            "Reusing existing connection to ladsweb.modaps.eosdis.nasa.gov:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 574155118 (548M) [application/x-hdf]\n",
            "Saving to: ‘./MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf’\n",
            "\n",
            "MOD01/2021/206/MOD0 100%[===================>] 547.56M  42.5MB/s    in 6.3s    \n",
            "\n",
            "2022-08-09 16:47:19 (87.5 MB/s) - ‘./MOD01/2021/206/MOD01.A2021206.0510.061.2021217151715.hdf’ saved [574155118/574155118]\n",
            "\n",
            "FINISHED --2022-08-09 16:47:19--\n",
            "Total wall clock time: 3m 26s\n",
            "Downloaded: 1 files, 548M in 6.3s (87.5 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e0qhyZwiMg2"
      },
      "source": [
        "# DOWNLOADING MOD10A.061"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvRYPgILiUz9"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/OUT/data/MOD10A1v6\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9uD7meghBMj"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# ----------------------------------------------------------------------------\n",
        "# NSIDC Data Download Script\n",
        "#\n",
        "# Copyright (c) 2022 Regents of the University of Colorado\n",
        "# Permission is hereby granted, free of charge, to any person obtaining\n",
        "# a copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "# The above copyright notice and this permission notice shall be included\n",
        "# in all copies or substantial portions of the Software.\n",
        "#\n",
        "# Tested in Python 2.7 and Python 3.4, 3.6, 3.7, 3.8, 3.9\n",
        "#\n",
        "# To run the script at a Linux, macOS, or Cygwin command-line terminal:\n",
        "#   $ python nsidc-data-download.py\n",
        "#\n",
        "# On Windows, open Start menu -> Run and type cmd. Then type:\n",
        "#     python nsidc-data-download.py\n",
        "#\n",
        "# The script will first search Earthdata for all matching files.\n",
        "# You will then be prompted for your Earthdata username/password\n",
        "# and the script will download the matching files.\n",
        "#\n",
        "# If you wish, you may store your Earthdata username/password in a .netrc\n",
        "# file in your $HOME directory and the script will automatically attempt to\n",
        "# read this file. The .netrc file should have the following format:\n",
        "#    machine urs.earthdata.nasa.gov login MYUSERNAME password MYPASSWORD\n",
        "# where 'MYUSERNAME' and 'MYPASSWORD' are your Earthdata credentials.\n",
        "#\n",
        "# Instead of a username/password, you may use an Earthdata bearer token.\n",
        "# To construct a bearer token, log into Earthdata and choose \"Generate Token\".\n",
        "# To use the token, when the script prompts for your username,\n",
        "# just press Return (Enter). You will then be prompted for your token.\n",
        "# You can store your bearer token in the .netrc file in the following format:\n",
        "#    machine urs.earthdata.nasa.gov login token password MYBEARERTOKEN\n",
        "# where 'MYBEARERTOKEN' is your Earthdata bearer token.\n",
        "#\n",
        "from __future__ import print_function\n",
        "\n",
        "import base64\n",
        "import getopt\n",
        "import itertools\n",
        "import json\n",
        "import math\n",
        "import netrc\n",
        "import os.path\n",
        "import ssl\n",
        "import sys\n",
        "import time\n",
        "from getpass import getpass\n",
        "\n",
        "try:\n",
        "    from urllib.parse import urlparse\n",
        "    from urllib.request import urlopen, Request, build_opener, HTTPCookieProcessor\n",
        "    from urllib.error import HTTPError, URLError\n",
        "except ImportError:\n",
        "    from urlparse import urlparse\n",
        "    from urllib2 import urlopen, Request, HTTPError, URLError, build_opener, HTTPCookieProcessor\n",
        "\n",
        "short_name = 'MOD10A2'\n",
        "version = '61'\n",
        "time_start = '2000-02-18T00:00:00Z'\n",
        "time_end = '2022-08-04T20:12:39Z'\n",
        "bounding_box = '75.67,31.13,77.84,32.59'\n",
        "polygon = ''\n",
        "filename_filter = ''\n",
        "url_list = []\n",
        "\n",
        "CMR_URL = 'https://cmr.earthdata.nasa.gov'\n",
        "URS_URL = 'https://urs.earthdata.nasa.gov'\n",
        "CMR_PAGE_SIZE = 2000\n",
        "CMR_FILE_URL = ('{0}/search/granules.json?provider=NSIDC_ECS'\n",
        "                '&sort_key[]=start_date&sort_key[]=producer_granule_id'\n",
        "                '&scroll=true&page_size={1}'.format(CMR_URL, CMR_PAGE_SIZE))\n",
        "\n",
        "\n",
        "def get_username():\n",
        "    username = 'kroy0001'\n",
        "    while not username:\n",
        "      # For Python 2/3 compatibility:\n",
        "      try:\n",
        "          do_input = raw_input  # noqa\n",
        "      except NameError:\n",
        "          do_input = input\n",
        "      username = do_input('Earthdata username (or press Return to use a bearer token): ')\n",
        "    return username\n",
        "\n",
        "\n",
        "def get_password():\n",
        "    password = '/#j%kWrPA,8.HRe'\n",
        "    while not password:\n",
        "        password = getpass('password: ')\n",
        "    return password\n",
        "\n",
        "\n",
        "def get_token():\n",
        "    token = ''\n",
        "    while not token:\n",
        "        token = getpass('bearer token: ')\n",
        "    return token\n",
        "\n",
        "\n",
        "def get_login_credentials():\n",
        "    \"\"\"Get user credentials from .netrc or prompt for input.\"\"\"\n",
        "    credentials = None\n",
        "    token = None\n",
        "\n",
        "    try:\n",
        "        info = netrc.netrc()\n",
        "        username, account, password = info.authenticators(urlparse(URS_URL).hostname)\n",
        "        if username == 'token':\n",
        "            token = password\n",
        "        else:\n",
        "            credentials = '{0}:{1}'.format(username, password)\n",
        "            credentials = base64.b64encode(credentials.encode('ascii')).decode('ascii')\n",
        "    except Exception:\n",
        "        username = None\n",
        "        password = None\n",
        "\n",
        "    if not username:\n",
        "        username = get_username()\n",
        "        if len(username):\n",
        "            password = get_password()\n",
        "            credentials = '{0}:{1}'.format(username, password)\n",
        "            credentials = base64.b64encode(credentials.encode('ascii')).decode('ascii')\n",
        "        else:\n",
        "            token = get_token()\n",
        "\n",
        "    return credentials, token\n",
        "\n",
        "\n",
        "def build_version_query_params(version):\n",
        "    desired_pad_length = 3\n",
        "    if len(version) > desired_pad_length:\n",
        "        print('Version string too long: \"{0}\"'.format(version))\n",
        "        quit()\n",
        "\n",
        "    version = str(int(version))  # Strip off any leading zeros\n",
        "    query_params = ''\n",
        "\n",
        "    while len(version) <= desired_pad_length:\n",
        "        padded_version = version.zfill(desired_pad_length)\n",
        "        query_params += '&version={0}'.format(padded_version)\n",
        "        desired_pad_length -= 1\n",
        "    return query_params\n",
        "\n",
        "\n",
        "def filter_add_wildcards(filter):\n",
        "    if not filter.startswith('*'):\n",
        "        filter = '*' + filter\n",
        "    if not filter.endswith('*'):\n",
        "        filter = filter + '*'\n",
        "    return filter\n",
        "\n",
        "\n",
        "def build_filename_filter(filename_filter):\n",
        "    filters = filename_filter.split(',')\n",
        "    result = '&options[producer_granule_id][pattern]=true'\n",
        "    for filter in filters:\n",
        "        result += '&producer_granule_id[]=' + filter_add_wildcards(filter)\n",
        "    return result\n",
        "\n",
        "\n",
        "def build_cmr_query_url(short_name, version, time_start, time_end,\n",
        "                        bounding_box=None, polygon=None,\n",
        "                        filename_filter=None):\n",
        "    params = '&short_name={0}'.format(short_name)\n",
        "    params += build_version_query_params(version)\n",
        "    params += '&temporal[]={0},{1}'.format(time_start, time_end)\n",
        "    if polygon:\n",
        "        params += '&polygon={0}'.format(polygon)\n",
        "    elif bounding_box:\n",
        "        params += '&bounding_box={0}'.format(bounding_box)\n",
        "    if filename_filter:\n",
        "        params += build_filename_filter(filename_filter)\n",
        "    return CMR_FILE_URL + params\n",
        "\n",
        "\n",
        "def get_speed(time_elapsed, chunk_size):\n",
        "    if time_elapsed <= 0:\n",
        "        return ''\n",
        "    speed = chunk_size / time_elapsed\n",
        "    if speed <= 0:\n",
        "        speed = 1\n",
        "    size_name = ('', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')\n",
        "    i = int(math.floor(math.log(speed, 1000)))\n",
        "    p = math.pow(1000, i)\n",
        "    return '{0:.1f}{1}B/s'.format(speed / p, size_name[i])\n",
        "\n",
        "\n",
        "def output_progress(count, total, status='', bar_len=60):\n",
        "    if total <= 0:\n",
        "        return\n",
        "    fraction = min(max(count / float(total), 0), 1)\n",
        "    filled_len = int(round(bar_len * fraction))\n",
        "    percents = int(round(100.0 * fraction))\n",
        "    bar = '=' * filled_len + ' ' * (bar_len - filled_len)\n",
        "    fmt = '  [{0}] {1:3d}%  {2}   '.format(bar, percents, status)\n",
        "    print('\\b' * (len(fmt) + 4), end='')  # clears the line\n",
        "    sys.stdout.write(fmt)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def cmr_read_in_chunks(file_object, chunk_size=1024 * 1024):\n",
        "    \"\"\"Read a file in chunks using a generator. Default chunk size: 1Mb.\"\"\"\n",
        "    while True:\n",
        "        data = file_object.read(chunk_size)\n",
        "        if not data:\n",
        "            break\n",
        "        yield data\n",
        "\n",
        "\n",
        "def get_login_response(url, credentials, token):\n",
        "    opener = build_opener(HTTPCookieProcessor())\n",
        "\n",
        "    req = Request(url)\n",
        "    if token:\n",
        "        req.add_header('Authorization', 'Bearer {0}'.format(token))\n",
        "    elif credentials:\n",
        "        try:\n",
        "            response = opener.open(req)\n",
        "            # We have a redirect URL - try again with authorization.\n",
        "            url = response.url\n",
        "        except HTTPError:\n",
        "            # No redirect - just try again with authorization.\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            print('Error{0}: {1}'.format(type(e), str(e)))\n",
        "            sys.exit(1)\n",
        "\n",
        "        req = Request(url)\n",
        "        req.add_header('Authorization', 'Basic {0}'.format(credentials))\n",
        "\n",
        "    try:\n",
        "        response = opener.open(req)\n",
        "    except HTTPError as e:\n",
        "        err = 'HTTP error {0}, {1}'.format(e.code, e.reason)\n",
        "        if 'Unauthorized' in e.reason:\n",
        "            if token:\n",
        "                err += ': Check your bearer token'\n",
        "            else:\n",
        "                err += ': Check your username and password'\n",
        "        print(err)\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        print('Error{0}: {1}'.format(type(e), str(e)))\n",
        "        sys.exit(1)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def cmr_download(urls, force=False, quiet=False):\n",
        "    \"\"\"Download files from list of urls.\"\"\"\n",
        "    if not urls:\n",
        "        return\n",
        "\n",
        "    url_count = len(urls)\n",
        "    if not quiet:\n",
        "        print('Downloading {0} files...'.format(url_count))\n",
        "    credentials = None\n",
        "    token = None\n",
        "\n",
        "    for index, url in enumerate(urls, start=1):\n",
        "        if not credentials and not token:\n",
        "            p = urlparse(url)\n",
        "            if p.scheme == 'https':\n",
        "                credentials, token = get_login_credentials()\n",
        "\n",
        "        filename = url.split('/')[-1]\n",
        "        if not quiet:\n",
        "            print('{0}/{1}: {2}'.format(str(index).zfill(len(str(url_count))),\n",
        "                                        url_count, filename))\n",
        "\n",
        "        try:\n",
        "            response = get_login_response(url, credentials, token)\n",
        "            length = int(response.headers['content-length'])\n",
        "            try:\n",
        "                if not force and length == os.path.getsize(filename):\n",
        "                    if not quiet:\n",
        "                        print('  File exists, skipping')\n",
        "                    continue\n",
        "            except OSError:\n",
        "                pass\n",
        "            count = 0\n",
        "            chunk_size = min(max(length, 1), 1024 * 1024)\n",
        "            max_chunks = int(math.ceil(length / chunk_size))\n",
        "            time_initial = time.time()\n",
        "            with open(filename, 'wb') as out_file:\n",
        "                for data in cmr_read_in_chunks(response, chunk_size=chunk_size):\n",
        "                    out_file.write(data)\n",
        "                    if not quiet:\n",
        "                        count = count + 1\n",
        "                        time_elapsed = time.time() - time_initial\n",
        "                        download_speed = get_speed(time_elapsed, count * chunk_size)\n",
        "                        output_progress(count, max_chunks, status=download_speed)\n",
        "            if not quiet:\n",
        "                print()\n",
        "        except HTTPError as e:\n",
        "            print('HTTP error {0}, {1}'.format(e.code, e.reason))\n",
        "        except URLError as e:\n",
        "            print('URL error: {0}'.format(e.reason))\n",
        "        except IOError:\n",
        "            raise\n",
        "\n",
        "\n",
        "def cmr_filter_urls(search_results):\n",
        "    \"\"\"Select only the desired data files from CMR response.\"\"\"\n",
        "    if 'feed' not in search_results or 'entry' not in search_results['feed']:\n",
        "        return []\n",
        "\n",
        "    entries = [e['links']\n",
        "               for e in search_results['feed']['entry']\n",
        "               if 'links' in e]\n",
        "    # Flatten \"entries\" to a simple list of links\n",
        "    links = list(itertools.chain(*entries))\n",
        "\n",
        "    urls = []\n",
        "    unique_filenames = set()\n",
        "    for link in links:\n",
        "        if 'href' not in link:\n",
        "            # Exclude links with nothing to download\n",
        "            continue\n",
        "        if 'inherited' in link and link['inherited'] is True:\n",
        "            # Why are we excluding these links?\n",
        "            continue\n",
        "        if 'rel' in link and 'data#' not in link['rel']:\n",
        "            # Exclude links which are not classified by CMR as \"data\" or \"metadata\"\n",
        "            continue\n",
        "\n",
        "        if 'title' in link and 'opendap' in link['title'].lower():\n",
        "            # Exclude OPeNDAP links--they are responsible for many duplicates\n",
        "            # This is a hack; when the metadata is updated to properly identify\n",
        "            # non-datapool links, we should be able to do this in a non-hack way\n",
        "            continue\n",
        "\n",
        "        filename = link['href'].split('/')[-1]\n",
        "        if filename in unique_filenames:\n",
        "            # Exclude links with duplicate filenames (they would overwrite)\n",
        "            continue\n",
        "        unique_filenames.add(filename)\n",
        "\n",
        "        urls.append(link['href'])\n",
        "\n",
        "    return urls\n",
        "\n",
        "\n",
        "def cmr_search(short_name, version, time_start, time_end,\n",
        "               bounding_box='', polygon='', filename_filter='', quiet=False):\n",
        "    \"\"\"Perform a scrolling CMR query for files matching input criteria.\"\"\"\n",
        "    cmr_query_url = build_cmr_query_url(short_name=short_name, version=version,\n",
        "                                        time_start=time_start, time_end=time_end,\n",
        "                                        bounding_box=bounding_box,\n",
        "                                        polygon=polygon, filename_filter=filename_filter)\n",
        "    if not quiet:\n",
        "        print('Querying for data:\\n\\t{0}\\n'.format(cmr_query_url))\n",
        "\n",
        "    cmr_scroll_id = None\n",
        "    ctx = ssl.create_default_context()\n",
        "    ctx.check_hostname = False\n",
        "    ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    urls = []\n",
        "    hits = 0\n",
        "    while True:\n",
        "        req = Request(cmr_query_url)\n",
        "        if cmr_scroll_id:\n",
        "            req.add_header('cmr-scroll-id', cmr_scroll_id)\n",
        "        try:\n",
        "            response = urlopen(req, context=ctx)\n",
        "        except Exception as e:\n",
        "            print('Error: ' + str(e))\n",
        "            sys.exit(1)\n",
        "        if not cmr_scroll_id:\n",
        "            # Python 2 and 3 have different case for the http headers\n",
        "            headers = {k.lower(): v for k, v in dict(response.info()).items()}\n",
        "            cmr_scroll_id = headers['cmr-scroll-id']\n",
        "            hits = int(headers['cmr-hits'])\n",
        "            if not quiet:\n",
        "                if hits > 0:\n",
        "                    print('Found {0} matches.'.format(hits))\n",
        "                else:\n",
        "                    print('Found no matches.')\n",
        "        search_page = response.read()\n",
        "        search_page = json.loads(search_page.decode('utf-8'))\n",
        "        url_scroll_results = cmr_filter_urls(search_page)\n",
        "        if not url_scroll_results:\n",
        "            break\n",
        "        if not quiet and hits > CMR_PAGE_SIZE:\n",
        "            print('.', end='')\n",
        "            sys.stdout.flush()\n",
        "        urls += url_scroll_results\n",
        "\n",
        "    if not quiet and hits > CMR_PAGE_SIZE:\n",
        "        print()\n",
        "    return urls\n",
        "\n",
        "\n",
        "def main(argv=None):\n",
        "    global short_name, version, time_start, time_end, bounding_box, \\\n",
        "        polygon, filename_filter, url_list\n",
        "\n",
        "    if argv is None:\n",
        "        argv = sys.argv[1:]\n",
        "\n",
        "    force = False\n",
        "    quiet = False\n",
        "    usage = 'usage: nsidc-download_***.py [--help, -h] [--force, -f] [--quiet, -q]'\n",
        "\n",
        "    try:\n",
        "        opts, args = getopt.getopt(argv, 'hfq', ['help', 'force', 'quiet'])\n",
        "        for opt, _arg in opts:\n",
        "            if opt in ('-f', '--force'):\n",
        "                force = True\n",
        "            elif opt in ('-q', '--quiet'):\n",
        "                quiet = True\n",
        "            elif opt in ('-h', '--help'):\n",
        "                print(usage)\n",
        "                sys.exit(0)\n",
        "    except getopt.GetoptError as e:\n",
        "        print(e.args[0])\n",
        "        print(usage)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Supply some default search parameters, just for testing purposes.\n",
        "    # These are only used if the parameters aren't filled in up above.\n",
        "    if 'short_name' in short_name:\n",
        "        short_name = 'ATL06'\n",
        "        version = '003'\n",
        "        time_start = '2018-10-14T00:00:00Z'\n",
        "        time_end = '2021-01-08T21:48:13Z'\n",
        "        bounding_box = ''\n",
        "        polygon = ''\n",
        "        filename_filter = '*ATL06_2020111121*'\n",
        "        url_list = []\n",
        "\n",
        "    try:\n",
        "        if not url_list:\n",
        "            url_list = cmr_search(short_name, version, time_start, time_end,\n",
        "                                  bounding_box=bounding_box, polygon=polygon,\n",
        "                                  filename_filter=filename_filter, quiet=quiet)\n",
        "\n",
        "        cmr_download(url_list, force=force, quiet=quiet)\n",
        "    except KeyboardInterrupt:\n",
        "        quit()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "#1284 seconds execution time"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NSIDC Data Editor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}