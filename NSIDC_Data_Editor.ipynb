{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1kaiser/test2022/blob/main/NSIDC_Data_Editor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tR28xKL2xHV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng_wcRuL252M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NbFxO-hu1Tx"
      },
      "source": [
        "# VIEW FIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sUj_Ezpy3CY"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/OUT/data/MOD10A1v6/MOD10A1.A2000055.h24v05.006.2016061160550.hdf /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3DCyp74URzd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Default title text { vertical-output: true }\n",
        "path = \"/content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf\" #@param {type:\"string\"}\n",
        "%cd /content\n",
        "!gdalinfo {path}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdal_translate HDF4_EOS:EOS_GRID:{path}:MOD_Grid_Snow_500m:NDSI /content/MOD10A1.A2000320.h24v05.006.2016069160102.img"
      ],
      "metadata": {
        "id": "4Ovv6ZM07_Bh",
        "outputId": "bb6f53bb-45ec-4508-c66f-5c2641fb9f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: The target file has a 'img' extension, which is normally used by the HFA, SRP drivers, but the requested output driver is GTiff. Is it really what you want?\n",
            "Input file size is 2400, 2400\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdaltransform -s_srs EPSG:6842 -t_srs WGS84 {path} {path}\n",
        "#!gdalwarp -t_srs \"+proj=longlat +datum=WGS84 +no_defs\" {path} reproj_vel_mosaic.tif"
      ],
      "metadata": {
        "id": "OY03pomN7bcJ",
        "outputId": "63c3f983-0f6b-4482-95a2-532cf3e63d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR 1: The transformation is already \"north up\" or a transformation between pixel/line and georeferenced coordinates cannot be computed for /content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf. There is no affine transformation and no GCPs. Specify transformation option SRC_METHOD=NO_GEOTRANSFORM to bypass this check.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyModis"
      ],
      "metadata": {
        "id": "70TAh20JybZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymodis\n",
        "subset = [1,0,0,1,0,0,0]\n",
        "pymodis.convertmodis_gdal.convertModisGDAL(path,path[:-4],subset,2400,outformat=\"GTiff\",epsg=32643).run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjHlV0o_ygp9",
        "outputId": "202031fd-aece-4234-df87-ae586647e02b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer HDF4_EOS:EOS_GRID:\"/content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf\":MOD_Grid_Snow_500m:NDSI_Snow_Cover reprojected\n",
            "Layer HDF4_EOS:EOS_GRID:\"/content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf\":MOD_Grid_Snow_500m:NDSI reprojected\n",
            "All layer for dataset '/content/MOD10A1.A2022217.h24v05.061.2022219035723.hdf' reprojected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdalinfo /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ0jZijluqKO",
        "outputId": "548c3827-fd58-4707-da09-5c23d8fd38db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: GTiff/GeoTIFF\n",
            "Files: /content/MOD10A1.A2022217.h24v05.061.2022219035723_ndsi-snow-cover.tif\n",
            "Size is 814, 517\n",
            "Coordinate System is:\n",
            "PROJCS[\"WGS 84 / UTM zone 43N\",\n",
            "    GEOGCS[\"WGS 84\",\n",
            "        DATUM[\"WGS_1984\",\n",
            "            SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
            "                AUTHORITY[\"EPSG\",\"7030\"]],\n",
            "            AUTHORITY[\"EPSG\",\"6326\"]],\n",
            "        PRIMEM[\"Greenwich\",0,\n",
            "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
            "        UNIT[\"degree\",0.0174532925199433,\n",
            "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
            "        AUTHORITY[\"EPSG\",\"4326\"]],\n",
            "    PROJECTION[\"Transverse_Mercator\"],\n",
            "    PARAMETER[\"latitude_of_origin\",0],\n",
            "    PARAMETER[\"central_meridian\",75],\n",
            "    PARAMETER[\"scale_factor\",0.9996],\n",
            "    PARAMETER[\"false_easting\",500000],\n",
            "    PARAMETER[\"false_northing\",0],\n",
            "    UNIT[\"metre\",1,\n",
            "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
            "    AXIS[\"Easting\",EAST],\n",
            "    AXIS[\"Northing\",NORTH],\n",
            "    AUTHORITY[\"EPSG\",\"32643\"]]\n",
            "Origin = (-51945.694007022306323,4558441.944021188654006)\n",
            "Pixel Size = (2400.000000000000000,-2400.000000000000000)\n",
            "Metadata:\n",
            "  ALGORITHMPACKAGEACCEPTANCEDATE=12-2005\n",
            "  ALGORITHMPACKAGEMATURITYCODE=Normal\n",
            "  ALGORITHMPACKAGENAME=MOD_PR10A1\n",
            "  ALGORITHMPACKAGEVERSION=5\n",
            "  AREA_OR_POINT=Area\n",
            "  ASSOCIATEDINSTRUMENTSHORTNAME.1=MODIS\n",
            "  ASSOCIATEDPLATFORMSHORTNAME.1=Terra\n",
            "  ASSOCIATEDSENSORSHORTNAME.1=MODIS\n",
            "  AUTOMATICQUALITYFLAG.1=Passed\n",
            "  AUTOMATICQUALITYFLAG.2=Passed\n",
            "  AUTOMATICQUALITYFLAGEXPLANATION.1=No automatic quality assessment done in the PGE\n",
            "  AUTOMATICQUALITYFLAGEXPLANATION.2=No automatic quality assessment done in the PGE\n",
            "  CHARACTERISTICBINANGULARSIZE=15.0\n",
            "  CHARACTERISTICBINSIZE=463.312716527778\n",
            "  DATACOLUMNS=2400\n",
            "  DATAROWS=2400\n",
            "  DAYNIGHTFLAG=Day\n",
            "  DESCRREVISION=6.1\n",
            "  EASTBOUNDINGCOORDINATE=91.3893886343225\n",
            "  EQUATORCROSSINGDATE.1=2022-08-05\n",
            "  EQUATORCROSSINGDATE.2=2022-08-05\n",
            "  EQUATORCROSSINGLONGITUDE.1=88.4749766409\n",
            "  EQUATORCROSSINGLONGITUDE.2=63.7539690699802\n",
            "  EQUATORCROSSINGTIME.1=04:23:11.149274\n",
            "  EQUATORCROSSINGTIME.2=06:02:04.180373\n",
            "  EXCLUSIONGRINGFLAG.1=N\n",
            "  GEOANYABNORMAL=False\n",
            "  GEOESTMAXRMSERROR=50.0\n",
            "  GLOBALGRIDCOLUMNS=86400\n",
            "  GLOBALGRIDROWS=43200\n",
            "  GRANULEBEGINNINGDATETIMEARRAY=2022-08-05T04:10:00.000000Z, 2022-08-05T04:15:00.000000Z, 2022-08-05T05:50:00.000000Z, 2022-08-05T07:25:00.000000Z\n",
            "  GRANULEDAYNIGHTFLAGARRAY=Day, Day, Day, Day\n",
            "  GRANULEENDINGDATETIMEARRAY=2022-08-05T04:15:00.000000Z, 2022-08-05T04:20:00.000000Z, 2022-08-05T05:55:00.000000Z, 2022-08-05T07:30:00.000000Z\n",
            "  GRANULENUMBERARRAY=52, 53, 72, 91, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n",
            "  GRANULEPOINTERARRAY=0, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n",
            "  GRINGPOINTLATITUDE.1=29.8921909961903, 40.0539553679112, 39.9987842793627, 29.8451444703661\n",
            "  GRINGPOINTLONGITUDE.1=69.0408206779493, 78.1118651853301, 91.398292082842, 80.7811959816983\n",
            "  GRINGPOINTSEQUENCENO.1=1, 2, 3, 4\n",
            "  HDFEOSVersion=HDFEOS_V2.19\n",
            "  HORIZONTALTILENUMBER=24\n",
            "  identifier_product_doi=10.5067/MODIS/MOD10A1.061\n",
            "  identifier_product_doi_authority=http://dx.doi.org\n",
            "  INPUTPOINTER=MOD10GA.A2022217.h24v05.061.2022219035052.hdf\n",
            "  INSTRUMENTNAME=Moderate Resolution Imaging Spectroradiometer\n",
            "  Key=0-100=NDSI snow, 200=missing data, 201=no decision, 211=night, 237=inland water, 239=ocean, 250=cloud, 254=detector saturated, 255=fill\n",
            "  L2GCoverageCalculationMethod=volume\n",
            "  L2GFirstLayerSelectionCriteria=order of input pointer\n",
            "  L2GNumberOfOverlapGranules=2\n",
            "  LOCALGRANULEID=MOD10A1.A2022217.h24v05.061.2022219035723.hdf\n",
            "  LOCALINPUTGRANULEID=MOD10GA.A2022217.h24v05.061.2022219035052.hdf\n",
            "  LOCALVERSIONID=SCF V6.0.1\n",
            "  LONGNAME=MODIS/Terra Snow Cover Daily L3 Global 500m SIN Grid\n",
            "  long_name=NDSI snow cover from best observation of the day\n",
            "  missing_value=200\n",
            "  NADIRDATARESOLUTION=500m\n",
            "  NORTHBOUNDINGCOORDINATE=39.9999999964079\n",
            "  NUMBEROFINPUTGRANULES=4\n",
            "  NUMBEROFORBITS=2\n",
            "  NUMBEROFOVERLAPGRANULES=2\n",
            "  ORBITNUMBER.1=120371\n",
            "  ORBITNUMBER.2=120372\n",
            "  ORBITNUMBERARRAY=120371, -1, 120372, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n",
            "  PARAMETERNAME.1=NDSI_Snow_Cover\n",
            "  PARAMETERNAME.2=Snow_Albedo_Daily_Tile\n",
            "  PGEVERSION=6.1.2\n",
            "  PLATFORMSHORTNAME=Terra\n",
            "  PROCESSINGCENTER=MODAPS\n",
            "  PROCESSINGDATETIME=2022-08-07T03:57:23.000Z\n",
            "  PROCESSINGENVIRONMENT=Linux minion20236 5.4.0-122-generic #138-Ubuntu SMP Wed Jun 22 15:00:31 UTC 2022 x86_64\n",
            "  PRODUCTIONDATETIME=2022-08-07T04:04:04.000Z\n",
            "  QAPERCENTCLOUDCOVER.1=68\n",
            "  QAPERCENTCLOUDCOVER.2=68\n",
            "  QAPERCENTGOODQUALITY=100\n",
            "  QAPERCENTMISSINGDATA.1=0\n",
            "  QAPERCENTMISSINGDATA.2=0\n",
            "  QAPERCENTOTHERQUALITY=0\n",
            "  RANGEBEGINNINGDATE=2022-08-05\n",
            "  RANGEBEGINNINGTIME=00:00:00\n",
            "  RANGEENDINGDATE=2022-08-05\n",
            "  RANGEENDINGTIME=23:59:59\n",
            "  REPROCESSINGACTUAL=reprocessed\n",
            "  REPROCESSINGPLANNED=further update is anticipated\n",
            "  SCIENCEQUALITYFLAG.1=Not Investigated\n",
            "  SCIENCEQUALITYFLAG.2=Not Investigated\n",
            "  SCIENCEQUALITYFLAGEXPLANATION.1=See http://landweb.nascom.nasa.gov/cgi-bin/QA_WWW/qaFlagPage.cgi?sat=terra for the product Science Quality status.\n",
            "  SCIENCEQUALITYFLAGEXPLANATION.2=See http://landweb.nascom.nasa.gov/cgi-bin/QA_WWW/qaFlagPage.cgi?sat=terra for the product Science Quality status.\n",
            "  SHORTNAME=MOD10A1\n",
            "  SNOWCOVERPERCENT=2\n",
            "  SOUTHBOUNDINGCOORDINATE=29.9999999973059\n",
            "  SPSOPARAMETERS=none\n",
            "  TileID=51024005\n",
            "  units=none\n",
            "  valid_range=0, 100\n",
            "  VERSIONID=61\n",
            "  VERTICALTILENUMBER=5\n",
            "  WESTBOUNDINGCOORDINATE=69.2820322946525\n",
            "  _FillValue=255\n",
            "Image Structure Metadata:\n",
            "  INTERLEAVE=BAND\n",
            "Corner Coordinates:\n",
            "Upper Left  (  -51945.694, 4558441.944) ( 68d26'24.47\"E, 40d59'24.68\"N)\n",
            "Lower Left  (  -51945.694, 3317641.944) ( 69d17'23.01\"E, 29d51'56.94\"N)\n",
            "Upper Right ( 1901654.306, 4558441.944) ( 91d23' 0.44\"E, 39d59'57.41\"N)\n",
            "Lower Right ( 1901654.306, 3317641.944) ( 89d20'26.36\"E, 29d12'24.21\"N)\n",
            "Center      (  924854.306, 3938041.944) ( 79d40'57.11\"E, 35d29'42.31\"N)\n",
            "Band 1 Block=814x10 Type=Byte, ColorInterp=Gray\n",
            "  NoData Value=255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdalwarp -of GTiff -t_srs \"EPSG:32643\" HDF4_EOS:EOS_GRID:{path}:MOD_Grid_Snow_500m:NDSI NDSI.tif\n",
        "!gdalwarp -of GTiff -t_srs \"EPSG:32643\" HDF4_EOS:EOS_GRID:{path}:MOD_Grid_Snow_500m:NDSI_Snow_Cover NSC.tif\n"
      ],
      "metadata": {
        "id": "BLeY3f1Xpkv7",
        "outputId": "6c13b7a3-bbb3-4b7c-9bca-8dd0211e1de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR 1: Translating source or target SRS failed:\n",
            "SR-ORG:6974\n",
            "Usage: gdalwarp [--help-general] [--formats]\n",
            "    [-s_srs srs_def] [-t_srs srs_def] [-to \"NAME=VALUE\"] [-novshiftgrid]\n",
            "    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n",
            "    [-refine_gcps tolerance [minimum_gcps]]\n",
            "    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n",
            "    [-ovr level|AUTO|AUTO-n|NONE] [-wo \"NAME=VALUE\"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n",
            "    [-srcnodata \"value [value...]\"] [-dstnodata \"value [value...]\"] -dstalpha\n",
            "    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n",
            "    [-cutline datasource] [-cl layer] [-cwhere expression]\n",
            "    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n",
            "    [-of format] [-co \"NAME=VALUE\"]* [-overwrite]\n",
            "    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n",
            "    [-doo NAME=VALUE]*\n",
            "    srcfile* dstfile\n",
            "\n",
            "Available resampling methods:\n",
            "    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n",
            "ERROR 1: Translating source or target SRS failed:\n",
            "SR-ORG:6974\n",
            "Usage: gdalwarp [--help-general] [--formats]\n",
            "    [-s_srs srs_def] [-t_srs srs_def] [-to \"NAME=VALUE\"] [-novshiftgrid]\n",
            "    [-order n | -tps | -rpc | -geoloc] [-et err_threshold]\n",
            "    [-refine_gcps tolerance [minimum_gcps]]\n",
            "    [-te xmin ymin xmax ymax] [-tr xres yres] [-tap] [-ts width height]\n",
            "    [-ovr level|AUTO|AUTO-n|NONE] [-wo \"NAME=VALUE\"] [-ot Byte/Int16/...] [-wt Byte/Int16]\n",
            "    [-srcnodata \"value [value...]\"] [-dstnodata \"value [value...]\"] -dstalpha\n",
            "    [-r resampling_method] [-wm memory_in_mb] [-multi] [-q]\n",
            "    [-cutline datasource] [-cl layer] [-cwhere expression]\n",
            "    [-csql statement] [-cblend dist_in_pixels] [-crop_to_cutline]\n",
            "    [-of format] [-co \"NAME=VALUE\"]* [-overwrite]\n",
            "    [-nomd] [-cvmd meta_conflict_value] [-setci] [-oo NAME=VALUE]*\n",
            "    [-doo NAME=VALUE]*\n",
            "    srcfile* dstfile\n",
            "\n",
            "Available resampling methods:\n",
            "    near (default), bilinear, cubic, cubicspline, lanczos, average, mode,  max, min, med, Q1, Q3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdalwarp -cutline /content/beasBasinShapeFile.shp \\\n",
        "  /content/NSC.tif \\\n",
        "  /content/outfile.tif "
      ],
      "metadata": {
        "id": "e-tVlczsYsLF",
        "outputId": "e8ba63fb-bafb-4d8c-f5f0-71aab8cc8418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating output file that is 5842P x 3708L.\n",
            "Processing input file /content/NSC.tif.\n",
            "Using internal nodata values (e.g. 255) for image /content/NSC.tif.\n",
            "Copying nodata values from source /content/NSC.tif to destination /content/outfile.tif.\n",
            "Warning 1: the source raster dataset has a SRS, but the cutline features\n",
            "not.  We assume that the cutline coordinates are expressed in the destination SRS.\n",
            "If not, cutline results may be incorrect.\n",
            "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install gdal\n",
        "import gdal\n",
        "gdal.Warp(\"/content/outfile.tif\",\"/content/NSC.tif\",cutlineDSName=\"/content/beasBasinShapeFile.shp\",cropToCutline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmj70XRDoU9x",
        "outputId": "91f7842e-0b4e-4507-b4f8-1a84365bedda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdal in /usr/local/lib/python3.7/dist-packages (2.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install gdal\n",
        "import gdal\n",
        "in_file = f\"/content/MOD10A1.A2000320.h24v05.006.2016069160102.hdf\" # raw MODIS HDF in sinusoid projection\n",
        "out_file = f\"/content/MOD10A1.A2000320.h24v05.006.2016069160102.tif\"\n",
        "    \n",
        "# open dataset\n",
        "dataset = gdal.Open(in_file,gdal.GA_ReadOnly)\n",
        "subdataset =  gdal.Open(dataset.GetSubDatasets()[0][0], gdal.GA_ReadOnly)\n",
        "\n",
        "# gdalwarp\n",
        "kwargs = {'format': 'GTiff', 'dstSRS': 'EPSG:32643'}\n",
        "ds = gdal.Warp(destNameOrDestDS=out_file,srcDSOrSrcDSTab=subdataset, **kwargs)\n",
        "print('done')\n",
        "del ds"
      ],
      "metadata": {
        "id": "Lj2FSFKMnnNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd85f29-4b7e-4623-a119-e038aead5e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdal in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/MOD10A1.A2000320.h24v05.006.2016069160102.tif\"\n",
        "# Open the file:\n",
        "raster = gdal.Open(filepath)\n",
        "\n",
        "# Check type of the variable 'raster'\n",
        "type(raster)\n",
        "# Projection\n",
        "raster.GetProjection()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "i-vC_vg0rZWU",
        "outputId": "c75e2930-9e07-4714-b347-8085e43691bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PROJCS[\"WGS 84 / UTM zone 43N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",75],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32643\"]]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensions\n",
        "raster.RasterXSize\n",
        "raster.RasterYSize\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmvZub88sMbF",
        "outputId": "bb766a20-8534-4782-ad7a-0d56f8ab59ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3708"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of bands\n",
        "raster.RasterCount\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drDiPPizsO4p",
        "outputId": "121fb5eb-81de-48aa-af76-a540b39b1606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metadata for the raster dataset\n",
        "raster.GetMetadata()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwa1iVAssRPQ",
        "outputId": "3eeb911b-9cc8-49ff-d7b5-4b94992b067d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ALGORITHMPACKAGEACCEPTANCEDATE': '12-2005',\n",
              " 'ALGORITHMPACKAGEMATURITYCODE': 'Normal',\n",
              " 'ALGORITHMPACKAGENAME': 'MOD_PR10A1',\n",
              " 'ALGORITHMPACKAGEVERSION': '5',\n",
              " 'AREA_OR_POINT': 'Area',\n",
              " 'ASSOCIATEDINSTRUMENTSHORTNAME.1': 'MODIS',\n",
              " 'ASSOCIATEDPLATFORMSHORTNAME.1': 'Terra',\n",
              " 'ASSOCIATEDSENSORSHORTNAME.1': 'MODIS',\n",
              " 'AUTOMATICQUALITYFLAG.1': 'Passed',\n",
              " 'AUTOMATICQUALITYFLAG.2': 'Passed',\n",
              " 'AUTOMATICQUALITYFLAGEXPLANATION.1': 'No automatic quality assessment done in the PGE',\n",
              " 'AUTOMATICQUALITYFLAGEXPLANATION.2': 'No automatic quality assessment done in the PGE',\n",
              " 'CHARACTERISTICBINANGULARSIZE': '15.0',\n",
              " 'CHARACTERISTICBINSIZE': '463.312716527778',\n",
              " 'DATACOLUMNS': '2400',\n",
              " 'DATAROWS': '2400',\n",
              " 'DAYNIGHTFLAG': 'Day',\n",
              " 'DESCRREVISION': '6.1',\n",
              " 'EASTBOUNDINGCOORDINATE': '91.3893886343225',\n",
              " 'EQUATORCROSSINGDATE.1': '2000-11-15',\n",
              " 'EQUATORCROSSINGDATE.2': '2000-11-15',\n",
              " 'EQUATORCROSSINGLONGITUDE.1': '80.6352068696377',\n",
              " 'EQUATORCROSSINGLONGITUDE.2': '55.9141728934938',\n",
              " 'EQUATORCROSSINGTIME.1': '05:20:30.197747',\n",
              " 'EQUATORCROSSINGTIME.2': '06:59:23.242687',\n",
              " 'EXCLUSIONGRINGFLAG.1': 'N',\n",
              " 'GEOANYABNORMAL': 'False',\n",
              " 'GEOESTMAXRMSERROR': '50.0',\n",
              " 'GLOBALGRIDCOLUMNS': '86400',\n",
              " 'GLOBALGRIDROWS': '43200',\n",
              " 'GRANULEBEGINNINGDATETIMEARRAY': '2000-11-15T05:05:00.000000Z, 2000-11-15T05:10:00.000000Z, 2000-11-15T06:45:00.000000Z, 2000-11-15T06:50:00.000000Z',\n",
              " 'GRANULEDAYNIGHTFLAGARRAY': 'Day, Day, Day, Day',\n",
              " 'GRANULEENDINGDATETIMEARRAY': '2000-11-15T05:10:00.000000Z, 2000-11-15T05:15:00.000000Z, 2000-11-15T06:50:00.000000Z, 2000-11-15T06:55:00.000000Z',\n",
              " 'GRANULENUMBERARRAY': '63, 64, 83, 84, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1',\n",
              " 'GRANULEPOINTERARRAY': '0, 1, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1',\n",
              " 'GRINGPOINTLATITUDE.1': '29.8921909961903, 40.0539553679112, 39.9987842793627, 29.8451444703661',\n",
              " 'GRINGPOINTLONGITUDE.1': '69.0408206779493, 78.1118651853301, 91.398292082842, 80.7811959816983',\n",
              " 'GRINGPOINTSEQUENCENO.1': '1, 2, 3, 4',\n",
              " 'HDFEOSVersion': 'HDFEOS_V2.17',\n",
              " 'HORIZONTALTILENUMBER': '24',\n",
              " 'INPUTPOINTER': 'MOD10GA.A2000320.h24v05.006.2016069155421.hdf',\n",
              " 'INSTRUMENTNAME': 'Moderate Resolution Imaging Spectroradiometer',\n",
              " 'Key': '0-100=NDSI snow, 200=missing data, 201=no decision, 211=night, 237=inland water, 239=ocean, 250=cloud, 254=detector saturated, 255=fill',\n",
              " 'L2GCoverageCalculationMethod': 'volume',\n",
              " 'L2GFirstLayerSelectionCriteria': 'order of input pointer',\n",
              " 'L2GNumberOfOverlapGranules': '4',\n",
              " 'LOCALGRANULEID': 'MOD10A1.A2000320.h24v05.006.2016069160102.hdf',\n",
              " 'LOCALINPUTGRANULEID': 'MOD10GA.A2000320.h24v05.006.2016069155421.hdf',\n",
              " 'LOCALVERSIONID': 'SCF V6.0.1',\n",
              " 'LONGNAME': 'MODIS/Terra Snow Cover Daily L3 Global 500m SIN Grid',\n",
              " 'NADIRDATARESOLUTION': '500m',\n",
              " 'NORTHBOUNDINGCOORDINATE': '39.9999999964079',\n",
              " 'NUMBEROFINPUTGRANULES': '4',\n",
              " 'NUMBEROFORBITS': '2',\n",
              " 'NUMBEROFOVERLAPGRANULES': '4',\n",
              " 'ORBITNUMBER.1': '4847',\n",
              " 'ORBITNUMBER.2': '4848',\n",
              " 'ORBITNUMBERARRAY': '4847, 4847, 4848, 4848, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1',\n",
              " 'PARAMETERNAME.1': 'NDSI_Snow_Cover',\n",
              " 'PARAMETERNAME.2': 'Snow_Albedo_Daily_Tile',\n",
              " 'PGEVERSION': '6.0.11',\n",
              " 'PLATFORMSHORTNAME': 'Terra',\n",
              " 'PROCESSINGCENTER': 'MODAPS',\n",
              " 'PROCESSINGDATETIME': '2016-03-09T16:01:02.000Z',\n",
              " 'PROCESSINGENVIRONMENT': 'Linux minion5675 2.6.18-407.el5 #1 SMP Wed Nov 11 08:12:41 EST 2015 x86_64',\n",
              " 'PRODUCTIONDATETIME': '2016-03-09T16:01:10.000Z',\n",
              " 'QAPERCENTCLOUDCOVER.1': '20',\n",
              " 'QAPERCENTCLOUDCOVER.2': '20',\n",
              " 'QAPERCENTGOODQUALITY': '100',\n",
              " 'QAPERCENTMISSINGDATA.1': '0',\n",
              " 'QAPERCENTMISSINGDATA.2': '0',\n",
              " 'QAPERCENTOTHERQUALITY': '0',\n",
              " 'RANGEBEGINNINGDATE': '2000-11-15',\n",
              " 'RANGEBEGINNINGTIME': '05:05:00.000000',\n",
              " 'RANGEENDINGDATE': '2000-11-15',\n",
              " 'RANGEENDINGTIME': '06:55:00.000000',\n",
              " 'REPROCESSINGACTUAL': 'reprocessed',\n",
              " 'REPROCESSINGPLANNED': 'further update is anticipated',\n",
              " 'SCIENCEQUALITYFLAG.1': 'Not Investigated',\n",
              " 'SCIENCEQUALITYFLAG.2': 'Not Investigated',\n",
              " 'SCIENCEQUALITYFLAGEXPLANATION.1': 'See http://landweb.nascom.nasa.gov/cgi-bin/QA_WWW/qaFlagPage.cgi?sat=terra for the product Science Quality status.',\n",
              " 'SCIENCEQUALITYFLAGEXPLANATION.2': 'See http://landweb.nascom.nasa.gov/cgi-bin/QA_WWW/qaFlagPage.cgi?sat=terra for the product Science Quality status.',\n",
              " 'SHORTNAME': 'MOD10A1',\n",
              " 'SNOWCOVERPERCENT': '9',\n",
              " 'SOUTHBOUNDINGCOORDINATE': '29.9999999973059',\n",
              " 'SPSOPARAMETERS': 'none',\n",
              " 'TileID': '51024005',\n",
              " 'VERSIONID': '6',\n",
              " 'VERTICALTILENUMBER': '5',\n",
              " 'WESTBOUNDINGCOORDINATE': '69.2820322946525',\n",
              " '_FillValue': '255',\n",
              " 'identifier_product_doi': '10.5067/MODIS/MOD10A1.006',\n",
              " 'identifier_product_doi_authority': 'http://dx.doi.org',\n",
              " 'long_name': 'NDSI snow cover from best observation of the day',\n",
              " 'missing_value': '200',\n",
              " 'units': 'none',\n",
              " 'valid_range': '0, 100'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the raster band as separate variable\n",
        "band = raster.GetRasterBand(1)\n",
        "\n",
        "# Check type of the variable 'band'\n",
        "type(band)\n",
        "\n",
        "# Data type of the values\n",
        "gdal.GetDataTypeName(band.DataType)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48NgK5P-sXVy",
        "outputId": "9d6d2ffb-60bb-4ea7-fabb-0935c9f77063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Byte'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute statistics if needed\n",
        "if band.GetMinimum() is None or band.GetMaximum()is None:\n",
        "    band.ComputeStatistics(0)\n",
        "    print(\"Statistics computed.\")\n",
        "\n",
        "# Fetch metadata for the band\n",
        "band.GetMetadata()\n",
        "\n",
        "# Print only selected metadata:\n",
        "print (\"[ NO DATA VALUE ] = \", band.GetNoDataValue()) # none\n",
        "print (\"[ MIN ] = \", band.GetMinimum())\n",
        "print (\"[ MAX ] = \", band.GetMaximum())"
      ],
      "metadata": {
        "id": "jg0aSZGRsiG2",
        "outputId": "9326b345-317f-4796-ee12-4683b21f07c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics computed.\n",
            "[ NO DATA VALUE ] =  255.0\n",
            "[ MIN ] =  0.0\n",
            "[ MAX ] =  250.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e0qhyZwiMg2"
      },
      "source": [
        "# DOWNLOADING MOD10A.061"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvRYPgILiUz9"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/OUT/data/MOD10A1v6\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9uD7meghBMj"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# ----------------------------------------------------------------------------\n",
        "# NSIDC Data Download Script\n",
        "#\n",
        "# Copyright (c) 2022 Regents of the University of Colorado\n",
        "# Permission is hereby granted, free of charge, to any person obtaining\n",
        "# a copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "# The above copyright notice and this permission notice shall be included\n",
        "# in all copies or substantial portions of the Software.\n",
        "#\n",
        "# Tested in Python 2.7 and Python 3.4, 3.6, 3.7, 3.8, 3.9\n",
        "#\n",
        "# To run the script at a Linux, macOS, or Cygwin command-line terminal:\n",
        "#   $ python nsidc-data-download.py\n",
        "#\n",
        "# On Windows, open Start menu -> Run and type cmd. Then type:\n",
        "#     python nsidc-data-download.py\n",
        "#\n",
        "# The script will first search Earthdata for all matching files.\n",
        "# You will then be prompted for your Earthdata username/password\n",
        "# and the script will download the matching files.\n",
        "#\n",
        "# If you wish, you may store your Earthdata username/password in a .netrc\n",
        "# file in your $HOME directory and the script will automatically attempt to\n",
        "# read this file. The .netrc file should have the following format:\n",
        "#    machine urs.earthdata.nasa.gov login MYUSERNAME password MYPASSWORD\n",
        "# where 'MYUSERNAME' and 'MYPASSWORD' are your Earthdata credentials.\n",
        "#\n",
        "# Instead of a username/password, you may use an Earthdata bearer token.\n",
        "# To construct a bearer token, log into Earthdata and choose \"Generate Token\".\n",
        "# To use the token, when the script prompts for your username,\n",
        "# just press Return (Enter). You will then be prompted for your token.\n",
        "# You can store your bearer token in the .netrc file in the following format:\n",
        "#    machine urs.earthdata.nasa.gov login token password MYBEARERTOKEN\n",
        "# where 'MYBEARERTOKEN' is your Earthdata bearer token.\n",
        "#\n",
        "from __future__ import print_function\n",
        "\n",
        "import base64\n",
        "import getopt\n",
        "import itertools\n",
        "import json\n",
        "import math\n",
        "import netrc\n",
        "import os.path\n",
        "import ssl\n",
        "import sys\n",
        "import time\n",
        "from getpass import getpass\n",
        "\n",
        "try:\n",
        "    from urllib.parse import urlparse\n",
        "    from urllib.request import urlopen, Request, build_opener, HTTPCookieProcessor\n",
        "    from urllib.error import HTTPError, URLError\n",
        "except ImportError:\n",
        "    from urlparse import urlparse\n",
        "    from urllib2 import urlopen, Request, HTTPError, URLError, build_opener, HTTPCookieProcessor\n",
        "\n",
        "short_name = 'MOD10A2'\n",
        "version = '61'\n",
        "time_start = '2000-02-18T00:00:00Z'\n",
        "time_end = '2022-08-04T20:12:39Z'\n",
        "bounding_box = '75.67,31.13,77.84,32.59'\n",
        "polygon = ''\n",
        "filename_filter = ''\n",
        "url_list = []\n",
        "\n",
        "CMR_URL = 'https://cmr.earthdata.nasa.gov'\n",
        "URS_URL = 'https://urs.earthdata.nasa.gov'\n",
        "CMR_PAGE_SIZE = 2000\n",
        "CMR_FILE_URL = ('{0}/search/granules.json?provider=NSIDC_ECS'\n",
        "                '&sort_key[]=start_date&sort_key[]=producer_granule_id'\n",
        "                '&scroll=true&page_size={1}'.format(CMR_URL, CMR_PAGE_SIZE))\n",
        "\n",
        "\n",
        "def get_username():\n",
        "    username = 'kroy0001'\n",
        "    while not username:\n",
        "      # For Python 2/3 compatibility:\n",
        "      try:\n",
        "          do_input = raw_input  # noqa\n",
        "      except NameError:\n",
        "          do_input = input\n",
        "      username = do_input('Earthdata username (or press Return to use a bearer token): ')\n",
        "    return username\n",
        "\n",
        "\n",
        "def get_password():\n",
        "    password = '/#j%kWrPA,8.HRe'\n",
        "    while not password:\n",
        "        password = getpass('password: ')\n",
        "    return password\n",
        "\n",
        "\n",
        "def get_token():\n",
        "    token = ''\n",
        "    while not token:\n",
        "        token = getpass('bearer token: ')\n",
        "    return token\n",
        "\n",
        "\n",
        "def get_login_credentials():\n",
        "    \"\"\"Get user credentials from .netrc or prompt for input.\"\"\"\n",
        "    credentials = None\n",
        "    token = None\n",
        "\n",
        "    try:\n",
        "        info = netrc.netrc()\n",
        "        username, account, password = info.authenticators(urlparse(URS_URL).hostname)\n",
        "        if username == 'token':\n",
        "            token = password\n",
        "        else:\n",
        "            credentials = '{0}:{1}'.format(username, password)\n",
        "            credentials = base64.b64encode(credentials.encode('ascii')).decode('ascii')\n",
        "    except Exception:\n",
        "        username = None\n",
        "        password = None\n",
        "\n",
        "    if not username:\n",
        "        username = get_username()\n",
        "        if len(username):\n",
        "            password = get_password()\n",
        "            credentials = '{0}:{1}'.format(username, password)\n",
        "            credentials = base64.b64encode(credentials.encode('ascii')).decode('ascii')\n",
        "        else:\n",
        "            token = get_token()\n",
        "\n",
        "    return credentials, token\n",
        "\n",
        "\n",
        "def build_version_query_params(version):\n",
        "    desired_pad_length = 3\n",
        "    if len(version) > desired_pad_length:\n",
        "        print('Version string too long: \"{0}\"'.format(version))\n",
        "        quit()\n",
        "\n",
        "    version = str(int(version))  # Strip off any leading zeros\n",
        "    query_params = ''\n",
        "\n",
        "    while len(version) <= desired_pad_length:\n",
        "        padded_version = version.zfill(desired_pad_length)\n",
        "        query_params += '&version={0}'.format(padded_version)\n",
        "        desired_pad_length -= 1\n",
        "    return query_params\n",
        "\n",
        "\n",
        "def filter_add_wildcards(filter):\n",
        "    if not filter.startswith('*'):\n",
        "        filter = '*' + filter\n",
        "    if not filter.endswith('*'):\n",
        "        filter = filter + '*'\n",
        "    return filter\n",
        "\n",
        "\n",
        "def build_filename_filter(filename_filter):\n",
        "    filters = filename_filter.split(',')\n",
        "    result = '&options[producer_granule_id][pattern]=true'\n",
        "    for filter in filters:\n",
        "        result += '&producer_granule_id[]=' + filter_add_wildcards(filter)\n",
        "    return result\n",
        "\n",
        "\n",
        "def build_cmr_query_url(short_name, version, time_start, time_end,\n",
        "                        bounding_box=None, polygon=None,\n",
        "                        filename_filter=None):\n",
        "    params = '&short_name={0}'.format(short_name)\n",
        "    params += build_version_query_params(version)\n",
        "    params += '&temporal[]={0},{1}'.format(time_start, time_end)\n",
        "    if polygon:\n",
        "        params += '&polygon={0}'.format(polygon)\n",
        "    elif bounding_box:\n",
        "        params += '&bounding_box={0}'.format(bounding_box)\n",
        "    if filename_filter:\n",
        "        params += build_filename_filter(filename_filter)\n",
        "    return CMR_FILE_URL + params\n",
        "\n",
        "\n",
        "def get_speed(time_elapsed, chunk_size):\n",
        "    if time_elapsed <= 0:\n",
        "        return ''\n",
        "    speed = chunk_size / time_elapsed\n",
        "    if speed <= 0:\n",
        "        speed = 1\n",
        "    size_name = ('', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y')\n",
        "    i = int(math.floor(math.log(speed, 1000)))\n",
        "    p = math.pow(1000, i)\n",
        "    return '{0:.1f}{1}B/s'.format(speed / p, size_name[i])\n",
        "\n",
        "\n",
        "def output_progress(count, total, status='', bar_len=60):\n",
        "    if total <= 0:\n",
        "        return\n",
        "    fraction = min(max(count / float(total), 0), 1)\n",
        "    filled_len = int(round(bar_len * fraction))\n",
        "    percents = int(round(100.0 * fraction))\n",
        "    bar = '=' * filled_len + ' ' * (bar_len - filled_len)\n",
        "    fmt = '  [{0}] {1:3d}%  {2}   '.format(bar, percents, status)\n",
        "    print('\\b' * (len(fmt) + 4), end='')  # clears the line\n",
        "    sys.stdout.write(fmt)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "def cmr_read_in_chunks(file_object, chunk_size=1024 * 1024):\n",
        "    \"\"\"Read a file in chunks using a generator. Default chunk size: 1Mb.\"\"\"\n",
        "    while True:\n",
        "        data = file_object.read(chunk_size)\n",
        "        if not data:\n",
        "            break\n",
        "        yield data\n",
        "\n",
        "\n",
        "def get_login_response(url, credentials, token):\n",
        "    opener = build_opener(HTTPCookieProcessor())\n",
        "\n",
        "    req = Request(url)\n",
        "    if token:\n",
        "        req.add_header('Authorization', 'Bearer {0}'.format(token))\n",
        "    elif credentials:\n",
        "        try:\n",
        "            response = opener.open(req)\n",
        "            # We have a redirect URL - try again with authorization.\n",
        "            url = response.url\n",
        "        except HTTPError:\n",
        "            # No redirect - just try again with authorization.\n",
        "            pass\n",
        "        except Exception as e:\n",
        "            print('Error{0}: {1}'.format(type(e), str(e)))\n",
        "            sys.exit(1)\n",
        "\n",
        "        req = Request(url)\n",
        "        req.add_header('Authorization', 'Basic {0}'.format(credentials))\n",
        "\n",
        "    try:\n",
        "        response = opener.open(req)\n",
        "    except HTTPError as e:\n",
        "        err = 'HTTP error {0}, {1}'.format(e.code, e.reason)\n",
        "        if 'Unauthorized' in e.reason:\n",
        "            if token:\n",
        "                err += ': Check your bearer token'\n",
        "            else:\n",
        "                err += ': Check your username and password'\n",
        "        print(err)\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        print('Error{0}: {1}'.format(type(e), str(e)))\n",
        "        sys.exit(1)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def cmr_download(urls, force=False, quiet=False):\n",
        "    \"\"\"Download files from list of urls.\"\"\"\n",
        "    if not urls:\n",
        "        return\n",
        "\n",
        "    url_count = len(urls)\n",
        "    if not quiet:\n",
        "        print('Downloading {0} files...'.format(url_count))\n",
        "    credentials = None\n",
        "    token = None\n",
        "\n",
        "    for index, url in enumerate(urls, start=1):\n",
        "        if not credentials and not token:\n",
        "            p = urlparse(url)\n",
        "            if p.scheme == 'https':\n",
        "                credentials, token = get_login_credentials()\n",
        "\n",
        "        filename = url.split('/')[-1]\n",
        "        if not quiet:\n",
        "            print('{0}/{1}: {2}'.format(str(index).zfill(len(str(url_count))),\n",
        "                                        url_count, filename))\n",
        "\n",
        "        try:\n",
        "            response = get_login_response(url, credentials, token)\n",
        "            length = int(response.headers['content-length'])\n",
        "            try:\n",
        "                if not force and length == os.path.getsize(filename):\n",
        "                    if not quiet:\n",
        "                        print('  File exists, skipping')\n",
        "                    continue\n",
        "            except OSError:\n",
        "                pass\n",
        "            count = 0\n",
        "            chunk_size = min(max(length, 1), 1024 * 1024)\n",
        "            max_chunks = int(math.ceil(length / chunk_size))\n",
        "            time_initial = time.time()\n",
        "            with open(filename, 'wb') as out_file:\n",
        "                for data in cmr_read_in_chunks(response, chunk_size=chunk_size):\n",
        "                    out_file.write(data)\n",
        "                    if not quiet:\n",
        "                        count = count + 1\n",
        "                        time_elapsed = time.time() - time_initial\n",
        "                        download_speed = get_speed(time_elapsed, count * chunk_size)\n",
        "                        output_progress(count, max_chunks, status=download_speed)\n",
        "            if not quiet:\n",
        "                print()\n",
        "        except HTTPError as e:\n",
        "            print('HTTP error {0}, {1}'.format(e.code, e.reason))\n",
        "        except URLError as e:\n",
        "            print('URL error: {0}'.format(e.reason))\n",
        "        except IOError:\n",
        "            raise\n",
        "\n",
        "\n",
        "def cmr_filter_urls(search_results):\n",
        "    \"\"\"Select only the desired data files from CMR response.\"\"\"\n",
        "    if 'feed' not in search_results or 'entry' not in search_results['feed']:\n",
        "        return []\n",
        "\n",
        "    entries = [e['links']\n",
        "               for e in search_results['feed']['entry']\n",
        "               if 'links' in e]\n",
        "    # Flatten \"entries\" to a simple list of links\n",
        "    links = list(itertools.chain(*entries))\n",
        "\n",
        "    urls = []\n",
        "    unique_filenames = set()\n",
        "    for link in links:\n",
        "        if 'href' not in link:\n",
        "            # Exclude links with nothing to download\n",
        "            continue\n",
        "        if 'inherited' in link and link['inherited'] is True:\n",
        "            # Why are we excluding these links?\n",
        "            continue\n",
        "        if 'rel' in link and 'data#' not in link['rel']:\n",
        "            # Exclude links which are not classified by CMR as \"data\" or \"metadata\"\n",
        "            continue\n",
        "\n",
        "        if 'title' in link and 'opendap' in link['title'].lower():\n",
        "            # Exclude OPeNDAP links--they are responsible for many duplicates\n",
        "            # This is a hack; when the metadata is updated to properly identify\n",
        "            # non-datapool links, we should be able to do this in a non-hack way\n",
        "            continue\n",
        "\n",
        "        filename = link['href'].split('/')[-1]\n",
        "        if filename in unique_filenames:\n",
        "            # Exclude links with duplicate filenames (they would overwrite)\n",
        "            continue\n",
        "        unique_filenames.add(filename)\n",
        "\n",
        "        urls.append(link['href'])\n",
        "\n",
        "    return urls\n",
        "\n",
        "\n",
        "def cmr_search(short_name, version, time_start, time_end,\n",
        "               bounding_box='', polygon='', filename_filter='', quiet=False):\n",
        "    \"\"\"Perform a scrolling CMR query for files matching input criteria.\"\"\"\n",
        "    cmr_query_url = build_cmr_query_url(short_name=short_name, version=version,\n",
        "                                        time_start=time_start, time_end=time_end,\n",
        "                                        bounding_box=bounding_box,\n",
        "                                        polygon=polygon, filename_filter=filename_filter)\n",
        "    if not quiet:\n",
        "        print('Querying for data:\\n\\t{0}\\n'.format(cmr_query_url))\n",
        "\n",
        "    cmr_scroll_id = None\n",
        "    ctx = ssl.create_default_context()\n",
        "    ctx.check_hostname = False\n",
        "    ctx.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    urls = []\n",
        "    hits = 0\n",
        "    while True:\n",
        "        req = Request(cmr_query_url)\n",
        "        if cmr_scroll_id:\n",
        "            req.add_header('cmr-scroll-id', cmr_scroll_id)\n",
        "        try:\n",
        "            response = urlopen(req, context=ctx)\n",
        "        except Exception as e:\n",
        "            print('Error: ' + str(e))\n",
        "            sys.exit(1)\n",
        "        if not cmr_scroll_id:\n",
        "            # Python 2 and 3 have different case for the http headers\n",
        "            headers = {k.lower(): v for k, v in dict(response.info()).items()}\n",
        "            cmr_scroll_id = headers['cmr-scroll-id']\n",
        "            hits = int(headers['cmr-hits'])\n",
        "            if not quiet:\n",
        "                if hits > 0:\n",
        "                    print('Found {0} matches.'.format(hits))\n",
        "                else:\n",
        "                    print('Found no matches.')\n",
        "        search_page = response.read()\n",
        "        search_page = json.loads(search_page.decode('utf-8'))\n",
        "        url_scroll_results = cmr_filter_urls(search_page)\n",
        "        if not url_scroll_results:\n",
        "            break\n",
        "        if not quiet and hits > CMR_PAGE_SIZE:\n",
        "            print('.', end='')\n",
        "            sys.stdout.flush()\n",
        "        urls += url_scroll_results\n",
        "\n",
        "    if not quiet and hits > CMR_PAGE_SIZE:\n",
        "        print()\n",
        "    return urls\n",
        "\n",
        "\n",
        "def main(argv=None):\n",
        "    global short_name, version, time_start, time_end, bounding_box, \\\n",
        "        polygon, filename_filter, url_list\n",
        "\n",
        "    if argv is None:\n",
        "        argv = sys.argv[1:]\n",
        "\n",
        "    force = False\n",
        "    quiet = False\n",
        "    usage = 'usage: nsidc-download_***.py [--help, -h] [--force, -f] [--quiet, -q]'\n",
        "\n",
        "    try:\n",
        "        opts, args = getopt.getopt(argv, 'hfq', ['help', 'force', 'quiet'])\n",
        "        for opt, _arg in opts:\n",
        "            if opt in ('-f', '--force'):\n",
        "                force = True\n",
        "            elif opt in ('-q', '--quiet'):\n",
        "                quiet = True\n",
        "            elif opt in ('-h', '--help'):\n",
        "                print(usage)\n",
        "                sys.exit(0)\n",
        "    except getopt.GetoptError as e:\n",
        "        print(e.args[0])\n",
        "        print(usage)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Supply some default search parameters, just for testing purposes.\n",
        "    # These are only used if the parameters aren't filled in up above.\n",
        "    if 'short_name' in short_name:\n",
        "        short_name = 'ATL06'\n",
        "        version = '003'\n",
        "        time_start = '2018-10-14T00:00:00Z'\n",
        "        time_end = '2021-01-08T21:48:13Z'\n",
        "        bounding_box = ''\n",
        "        polygon = ''\n",
        "        filename_filter = '*ATL06_2020111121*'\n",
        "        url_list = []\n",
        "\n",
        "    try:\n",
        "        if not url_list:\n",
        "            url_list = cmr_search(short_name, version, time_start, time_end,\n",
        "                                  bounding_box=bounding_box, polygon=polygon,\n",
        "                                  filename_filter=filename_filter, quiet=quiet)\n",
        "\n",
        "        cmr_download(url_list, force=force, quiet=quiet)\n",
        "    except KeyboardInterrupt:\n",
        "        quit()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "#1284 seconds execution time"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NSIDC Data Editor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}